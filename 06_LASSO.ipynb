{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LASSO Deconvolution v3 - Mass Channels\n",
    "\n",
    "**Approach:** Use Prosit predictions as templates (design matrix X) to estimate mixing coefficients β for chimeric spectra.\n",
    "\n",
    "**Method:**\n",
    "- **Channels:** Unique m/z values from all Prosit predictions (mass channels)\n",
    "- **Matching:** 20 ppm tolerance for observed ↔ predicted\n",
    "- **Model:** LASSO (L1 regularization) with non-negativity constraint\n",
    "- **Validation:** Prosit quality check using existing prosit_cosine column\n",
    "\n",
    "**Hypothesis:**\n",
    "1. β correlates with FragShare (r > 0.6)\n",
    "2. β weakly correlates with MS1 (r < 0.3)\n",
    "3. β outperforms Hyperscore for ranking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup & Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mkdir -p failed for path /user/antwerpen/211/vsc21150/.cache/matplotlib: [Errno 122] Disk quota exceeded: '/user/antwerpen/211/vsc21150/.cache/matplotlib'\n",
      "Matplotlib created a temporary cache directory at /tmp/matplotlib-9el98e3n because there was an issue with the default path (/user/antwerpen/211/vsc21150/.cache/matplotlib); it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.\n",
      "Fontconfig error: No writable cache directories\n",
      "Fontconfig error: No writable cache directories\n",
      "Fontconfig error: No writable cache directories\n",
      "Fontconfig error: No writable cache directories\n",
      "Fontconfig error: No writable cache directories\n",
      "Fontconfig error: No writable cache directories\n",
      "Fontconfig error: No writable cache directories\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "LASSO DECONVOLUTION v3 - MASS CHANNELS\n",
      "======================================================================\n",
      "Output: /data/antwerpen/211/vsc21150/Exploring-Fragmentation-Competion-in-Proteomics-Data-to-Decode-Chimeric-Spectra/v.3.0.0/analysis/07_lasso_deconvolution\n",
      "Cores:  64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/antwerpen/211/vsc21150/Exploring-Fragmentation-Competion-in-Proteomics-Data-to-Decode-Chimeric-Spectra/.venv/lib64/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import pickle\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from multiprocessing import Pool, cpu_count\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.auto import tqdm\n",
    "from scipy.optimize import nnls\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Paths\n",
    "PROJECT_DIR = Path('/data/antwerpen/211/vsc21150/Exploring-Fragmentation-Competion-in-Proteomics-Data-to-Decode-Chimeric-Spectra/v.3.0.0')\n",
    "DATA_DIR = PROJECT_DIR / 'processed_data'\n",
    "CACHE_DIR = PROJECT_DIR / 'cache'\n",
    "PLOT_DIR = PROJECT_DIR / 'plots'\n",
    "OUTPUT_DIR = PROJECT_DIR / 'analysis' / '07_lasso_deconvolution'\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "(OUTPUT_DIR / 'figures').mkdir(exist_ok=True)\n",
    "\n",
    "# Config\n",
    "CONFIG = {\n",
    "    'TOL_PPM': 20,\n",
    "    'LAMBDA_GRID': np.logspace(-6, 0, 30),\n",
    "    'N_FOLDS': 5,\n",
    "    'TRAIN_RATIO': 0.7,\n",
    "    'RANDOM_SEED': 42,\n",
    "    'MIN_CHANNELS': 5,\n",
    "    'MIN_NONZERO': 3,\n",
    "    'MIN_PSMS': 2,\n",
    "}\n",
    "\n",
    "N_CORES = min(64, cpu_count())\n",
    "np.random.seed(CONFIG['RANDOM_SEED'])\n",
    "\n",
    "plt.rcParams['figure.dpi'] = 120\n",
    "plt.rcParams['font.size'] = 11\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"LASSO DECONVOLUTION v3 - MASS CHANNELS\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Output: {OUTPUT_DIR}\")\n",
    "print(f\"Cores:  {N_CORES}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ scikit-learn ready\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "INSTALL_PATH = \"/data/antwerpen/211/vsc21150/python_packages\"\n",
    "os.makedirs(INSTALL_PATH, exist_ok=True)\n",
    "\n",
    "subprocess.run([\n",
    "    sys.executable, '-m', 'pip', 'install', 'scikit-learn',\n",
    "    f'--target={INSTALL_PATH}', '-q'\n",
    "], check=False, capture_output=True)\n",
    "\n",
    "sys.path.insert(0, INSTALL_PATH)\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "print(\"✓ scikit-learn ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Utility functions defined\n"
     ]
    }
   ],
   "source": [
    "def cosine_similarity(a: np.ndarray, b: np.ndarray) -> float:\n",
    "    \"\"\"Cosine similarity between two vectors.\"\"\"\n",
    "    norm_a = np.linalg.norm(a)\n",
    "    norm_b = np.linalg.norm(b)\n",
    "    if norm_a == 0 or norm_b == 0:\n",
    "        return 0.0\n",
    "    return float(np.dot(a, b) / (norm_a * norm_b))\n",
    "\n",
    "\n",
    "def find_match_idx(query_mz: float, ref_mz: np.ndarray, tol_ppm: float) -> int:\n",
    "    \"\"\"Find index of closest match within ppm tolerance. Returns -1 if none.\"\"\"\n",
    "    if len(ref_mz) == 0:\n",
    "        return -1\n",
    "    tol = query_mz * tol_ppm / 1e6\n",
    "    diffs = np.abs(ref_mz - query_mz)\n",
    "    idx = np.argmin(diffs)\n",
    "    return idx if diffs[idx] <= tol else -1\n",
    "\n",
    "\n",
    "def parse_scan_from_spectrum_key(spec_key: str) -> tuple:\n",
    "    \"\"\"Extract (mzml_name, scan) from spectrum_key.\"\"\"\n",
    "    parts = spec_key.split('::')\n",
    "    if len(parts) != 2:\n",
    "        return None, -1\n",
    "    \n",
    "    mzml_name = parts[0]\n",
    "    \n",
    "    # Add .mzML extension if missing\n",
    "    if not mzml_name.endswith('.mzML'):\n",
    "        mzml_name = mzml_name + '.mzML'\n",
    "    \n",
    "    try:\n",
    "        scan = int(parts[1])\n",
    "        return mzml_name, scan\n",
    "    except ValueError:\n",
    "        return mzml_name, -1\n",
    "\n",
    "\n",
    "print(\"✓ Utility functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "  PSMs: 1,132,669\n",
      "  Prosit cache: 27,907\n",
      "  Spectra: 955,800\n",
      "  Singleton: 296,582\n",
      "  Chimeric:  314,795\n",
      "✓ Data loaded\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading data...\")\n",
    "\n",
    "# PSM data\n",
    "df = pd.read_csv(CACHE_DIR / 'psm_annotated_final.csv')\n",
    "print(f\"  PSMs: {len(df):,}\")\n",
    "\n",
    "# Prosit predictions\n",
    "with open(CACHE_DIR / 'prosit_cache.pkl', 'rb') as f:\n",
    "    prosit_cache = pickle.load(f)\n",
    "print(f\"  Prosit cache: {len(prosit_cache):,}\")\n",
    "\n",
    "# MS2 spectra\n",
    "with open(CACHE_DIR / 'spectra_dict.pkl', 'rb') as f:\n",
    "    spectra_dict = pickle.load(f)\n",
    "print(f\"  Spectra: {len(spectra_dict):,}\")\n",
    "\n",
    "# Classify\n",
    "psm_counts = df.groupby('spectrum_key').size()\n",
    "singleton_spectra = set(psm_counts[psm_counts == 1].index)\n",
    "chimeric_spectra = set(psm_counts[psm_counts >= CONFIG['MIN_PSMS']].index)\n",
    "\n",
    "print(f\"  Singleton: {len(singleton_spectra):,}\")\n",
    "print(f\"  Chimeric:  {len(chimeric_spectra):,}\")\n",
    "print(\"✓ Data loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Prosit Quality Check (SIMPLIFIED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "PROSIT QUALITY CHECK\n",
      "======================================================================\n",
      "Prosit quality (from existing data):\n",
      "  Evaluated: 296,582 singletons\n",
      "  Mean:   0.7436 ± 0.2423\n",
      "  Median: 0.8359\n",
      "  >0.5:   81.5%\n",
      "  >0.7:   66.2%\n",
      "\n",
      "⚠️  NOTE: Prosit quality = 0.744 is moderate.\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"PROSIT QUALITY CHECK\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "if 'prosit_cosine' in df.columns:\n",
    "    # Use existing data from 05_prosit.ipynb\n",
    "    df_singleton = df[df['spectrum_key'].isin(singleton_spectra)].copy()\n",
    "    cos_vals = df_singleton['prosit_cosine'].dropna()\n",
    "    \n",
    "    if len(cos_vals) > 0:\n",
    "        PROSIT_QUALITY = cos_vals.mean()\n",
    "        print(f\"Prosit quality (from existing data):\")\n",
    "        print(f\"  Evaluated: {len(cos_vals):,} singletons\")\n",
    "        print(f\"  Mean:   {PROSIT_QUALITY:.4f} ± {cos_vals.std():.4f}\")\n",
    "        print(f\"  Median: {cos_vals.median():.4f}\")\n",
    "        print(f\"  >0.5:   {100*(cos_vals > 0.5).mean():.1f}%\")\n",
    "        print(f\"  >0.7:   {100*(cos_vals > 0.7).mean():.1f}%\")\n",
    "        \n",
    "        # GATE\n",
    "        if PROSIT_QUALITY < 0.6:\n",
    "            print(f\"\\n⚠️  WARNING: Prosit quality = {PROSIT_QUALITY:.3f} < 0.6!\")\n",
    "            print(\"    LASSO deconvolution may be unreliable.\")\n",
    "        elif PROSIT_QUALITY < 0.75:\n",
    "            print(f\"\\n⚠️  NOTE: Prosit quality = {PROSIT_QUALITY:.3f} is moderate.\")\n",
    "        else:\n",
    "            print(f\"\\n✓ Prosit quality = {PROSIT_QUALITY:.3f} is good!\")\n",
    "    else:\n",
    "        print(\"⚠️  No singleton Prosit data, skipping quality gate\")\n",
    "        PROSIT_QUALITY = np.nan\n",
    "else:\n",
    "    print(\"⚠️  prosit_cosine not found! Run 05_prosit.ipynb first.\")\n",
    "    PROSIT_QUALITY = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "PROSIT QUALITY CHECK\n",
      "======================================================================\n",
      "Prosit coverage on CHIMERIC spectra:\n",
      "  Total PSMs:     836,087\n",
      "  With Prosit:    835,809\n",
      "  Coverage:       100.0%\n",
      "\n",
      "Prosit quality on chimeric PSMs:\n",
      "  Evaluated: 836,087\n",
      "  Mean:   0.6286 ± 0.2515\n",
      "  Median: 0.6542\n",
      "  >0.5:   67.3%\n",
      "  >0.7:   44.7%\n",
      "\n",
      "⚠️  NOTE: Prosit quality = 0.629 is moderate.\n",
      "\n",
      "✓ Prosit coverage = 100.0% is good!\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"PROSIT QUALITY CHECK\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Check Prosit coverage on CHIMERIC spectra (what matters for LASSO)\n",
    "df_chimeric_check = df[df['spectrum_key'].isin(chimeric_spectra)].copy()\n",
    "total_chimeric_psms = len(df_chimeric_check)\n",
    "\n",
    "# Count PSMs with Prosit predictions\n",
    "psms_with_prosit = 0\n",
    "for _, row in df_chimeric_check.iterrows():\n",
    "    key = (row['Peptide'], int(row['Charge']))\n",
    "    if key in prosit_cache:\n",
    "        psms_with_prosit += 1\n",
    "\n",
    "prosit_coverage = psms_with_prosit / total_chimeric_psms if total_chimeric_psms > 0 else 0\n",
    "\n",
    "print(f\"Prosit coverage on CHIMERIC spectra:\")\n",
    "print(f\"  Total PSMs:     {total_chimeric_psms:,}\")\n",
    "print(f\"  With Prosit:    {psms_with_prosit:,}\")\n",
    "print(f\"  Coverage:       {100*prosit_coverage:.1f}%\")\n",
    "\n",
    "# Check quality if prosit_cosine exists\n",
    "if 'prosit_cosine' in df.columns:\n",
    "    cos_vals_chimeric = df_chimeric_check['prosit_cosine'].dropna()\n",
    "    if len(cos_vals_chimeric) > 0:\n",
    "        PROSIT_QUALITY = cos_vals_chimeric.mean()\n",
    "        print(f\"\\nProsit quality on chimeric PSMs:\")\n",
    "        print(f\"  Evaluated: {len(cos_vals_chimeric):,}\")\n",
    "        print(f\"  Mean:   {PROSIT_QUALITY:.4f} ± {cos_vals_chimeric.std():.4f}\")\n",
    "        print(f\"  Median: {cos_vals_chimeric.median():.4f}\")\n",
    "        print(f\"  >0.5:   {100*(cos_vals_chimeric > 0.5).mean():.1f}%\")\n",
    "        print(f\"  >0.7:   {100*(cos_vals_chimeric > 0.7).mean():.1f}%\")\n",
    "        \n",
    "        # GATE\n",
    "        if PROSIT_QUALITY < 0.6:\n",
    "            print(f\"\\n⚠️  WARNING: Prosit quality = {PROSIT_QUALITY:.3f} < 0.6!\")\n",
    "            print(\"    LASSO deconvolution may be unreliable.\")\n",
    "        elif PROSIT_QUALITY < 0.75:\n",
    "            print(f\"\\n⚠️  NOTE: Prosit quality = {PROSIT_QUALITY:.3f} is moderate.\")\n",
    "        else:\n",
    "            print(f\"\\n✓ Prosit quality = {PROSIT_QUALITY:.3f} is good!\")\n",
    "    else:\n",
    "        print(\"\\n⚠️  No Prosit cosine data available\")\n",
    "        PROSIT_QUALITY = np.nan\n",
    "else:\n",
    "    print(\"\\n⚠️  prosit_cosine column not found\")\n",
    "    PROSIT_QUALITY = np.nan\n",
    "\n",
    "# Coverage gate\n",
    "if prosit_coverage < 0.8:\n",
    "    print(f\"\\n⚠️  WARNING: Prosit coverage = {prosit_coverage:.1%} < 80%!\")\n",
    "    print(\"    Many chimeric PSMs will be skipped.\")\n",
    "else:\n",
    "    print(f\"\\n✓ Prosit coverage = {prosit_coverage:.1%} is good!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Design Matrix Construction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix Building (SLURM Job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shared data exists: 4371.9 MB\n",
      "Job 3027399 submitted\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "BASE_DIR = Path('/data/antwerpen/211/vsc21150/Exploring-Fragmentation-Competion-in-Proteomics-Data-to-Decode-Chimeric-Spectra')\n",
    "CACHE_DIR = BASE_DIR / 'cache'\n",
    "MATRIX_CACHE = CACHE_DIR / 'spectra_data_chimerys.pkl'\n",
    "PYTHON_SCRIPT = CACHE_DIR / 'matrix_build_chimerys.py'\n",
    "SLURM_SCRIPT = CACHE_DIR / 'run_matrix_chimerys.slurm'\n",
    "SHARED_DATA = CACHE_DIR / 'matrix_job_data.pkl'\n",
    "\n",
    "# Cancel any running jobs\n",
    "subprocess.run(['scancel', '-n', 'matrix_chimerys'], capture_output=True)\n",
    "\n",
    "# Prepare shared data if not exists\n",
    "if not SHARED_DATA.exists():\n",
    "    TARGET_SIZE = 100000\n",
    "    df_chimeric = df[df['spectrum_key'].isin(chimeric_spectra)].copy()\n",
    "    psm_counts = df_chimeric.groupby('spectrum_key').size()\n",
    "    \n",
    "    strata = {n: psm_counts[psm_counts == n].index.tolist() for n in range(2, 20)}\n",
    "    selected = []\n",
    "    for n in range(6, 21):\n",
    "        if strata.get(n): selected.extend(strata[n])\n",
    "    \n",
    "    remaining = TARGET_SIZE - len(selected)\n",
    "    weights = {2: 1, 3: 2, 4: 3, 5: 4}\n",
    "    total_w = sum(weights[n] * len(strata.get(n, [])) for n in weights)\n",
    "    \n",
    "    for n in [2, 3, 4, 5]:\n",
    "        if not strata.get(n): continue\n",
    "        alloc = min(int(remaining * weights[n] * len(strata[n]) / total_w), len(strata[n]))\n",
    "        np.random.seed(CONFIG['RANDOM_SEED'] + n)\n",
    "        selected.extend(np.random.choice(strata[n], alloc, replace=False).tolist())\n",
    "    \n",
    "    df_chimeric = df_chimeric[df_chimeric['spectrum_key'].isin(selected)]\n",
    "    psm_groups = {k: g.to_dict('records') for k, g in df_chimeric.groupby('spectrum_key')}\n",
    "    \n",
    "    with open(SHARED_DATA, 'wb') as f:\n",
    "        pickle.dump({\n",
    "            'unique_chimeric': selected, 'psm_groups': psm_groups,\n",
    "            'spectra_dict': spectra_dict, 'prosit_cache': prosit_cache, 'CONFIG': CONFIG\n",
    "        }, f)\n",
    "    print(f\"Prepared {len(selected):,} spectra | {SHARED_DATA.stat().st_size/1e6:.1f} MB\")\n",
    "else:\n",
    "    print(f\"Shared data exists: {SHARED_DATA.stat().st_size/1e6:.1f} MB\")\n",
    "\n",
    "# Python script with CHIMERYS-style matrix construction\n",
    "python_code = f'''#!/usr/bin/env python\n",
    "import os\n",
    "os.environ['NUMBA_CACHE_DIR'] = '/tmp'\n",
    "import numpy as np\n",
    "import pickle\n",
    "from multiprocessing import Pool\n",
    "\n",
    "with open(\"{SHARED_DATA}\", 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "unique_chimeric = data['unique_chimeric']\n",
    "psm_groups = data['psm_groups']\n",
    "spectra_dict = data['spectra_dict']\n",
    "prosit_cache = data['prosit_cache']\n",
    "CONFIG = data['CONFIG']\n",
    "del data\n",
    "print(f\"Loaded {{len(unique_chimeric):,}} spectra\", flush=True)\n",
    "\n",
    "def parse_scan(spec_key):\n",
    "    if '::' in spec_key:\n",
    "        parts = spec_key.rsplit('::', 1)\n",
    "        mzml = parts[0] + '.mzML' if not parts[0].endswith('.mzML') else parts[0]\n",
    "        return mzml, int(parts[1])\n",
    "    return None, -1\n",
    "\n",
    "def build_matrix_chimerys(obs_mz, obs_int, prosit_list, tol_ppm, min_channels=3):\n",
    "    \"\"\"CHIMERYS-style: only Prosit channels, no unmatched observed peaks.\"\"\"\n",
    "    n_pep = len(prosit_list)\n",
    "    if n_pep == 0:\n",
    "        return None, None, None\n",
    "    \n",
    "    # Collect all Prosit peaks with per-peptide normalization\n",
    "    p_mz, p_int, p_idx = [], [], []\n",
    "    for j, p in enumerate(prosit_list):\n",
    "        mz_arr = np.array(p['mz'])\n",
    "        int_arr = np.array(p['int'])\n",
    "        if int_arr.sum() > 0:\n",
    "            int_arr = int_arr / int_arr.sum()\n",
    "        p_mz.extend(mz_arr)\n",
    "        p_int.extend(int_arr)\n",
    "        p_idx.extend([j] * len(mz_arr))\n",
    "    \n",
    "    p_mz = np.array(p_mz)\n",
    "    p_int = np.array(p_int)\n",
    "    p_idx = np.array(p_idx)\n",
    "    \n",
    "    if len(p_mz) == 0:\n",
    "        return None, None, None\n",
    "    \n",
    "    # Sort by m/z\n",
    "    sort_idx = np.argsort(p_mz)\n",
    "    p_mz = p_mz[sort_idx]\n",
    "    p_int = p_int[sort_idx]\n",
    "    p_idx = p_idx[sort_idx]\n",
    "    \n",
    "    # Group into channels (merge peaks within tolerance)\n",
    "    channels = []\n",
    "    channel_contrib = []\n",
    "    \n",
    "    curr_mz = p_mz[0]\n",
    "    curr_contrib = [(p_idx[0], p_int[0])]\n",
    "    \n",
    "    for i in range(1, len(p_mz)):\n",
    "        tol = curr_mz * tol_ppm / 1e6\n",
    "        if abs(p_mz[i] - curr_mz) <= tol:\n",
    "            curr_contrib.append((p_idx[i], p_int[i]))\n",
    "            curr_mz = (curr_mz + p_mz[i]) / 2\n",
    "        else:\n",
    "            channels.append(curr_mz)\n",
    "            channel_contrib.append(curr_contrib)\n",
    "            curr_mz = p_mz[i]\n",
    "            curr_contrib = [(p_idx[i], p_int[i])]\n",
    "    \n",
    "    channels.append(curr_mz)\n",
    "    channel_contrib.append(curr_contrib)\n",
    "    \n",
    "    ch_mz = np.array(channels)\n",
    "    n_ch = len(ch_mz)\n",
    "    \n",
    "    if n_ch < min_channels:\n",
    "        return None, None, None\n",
    "    \n",
    "    # Build X matrix\n",
    "    X = np.zeros((n_ch, n_pep))\n",
    "    for k, contrib in enumerate(channel_contrib):\n",
    "        for pep_idx, intensity in contrib:\n",
    "            X[k, pep_idx] += intensity\n",
    "    \n",
    "    # Build y: match observed to channels\n",
    "    y = np.zeros(n_ch)\n",
    "    for k in range(n_ch):\n",
    "        tol = ch_mz[k] * tol_ppm / 1e6\n",
    "        diffs = np.abs(obs_mz - ch_mz[k])\n",
    "        if len(diffs) > 0:\n",
    "            min_idx = np.argmin(diffs)\n",
    "            if diffs[min_idx] <= tol:\n",
    "                y[k] = obs_int[min_idx]\n",
    "    \n",
    "    # Normalize y\n",
    "    if y.sum() > 0:\n",
    "        y = y / y.sum()\n",
    "    else:\n",
    "        return None, None, None\n",
    "    \n",
    "    return y, X, ch_mz\n",
    "\n",
    "def process(spec_key):\n",
    "    mzml, scan = parse_scan(spec_key)\n",
    "    if scan < 0 or (mzml, scan) not in spectra_dict:\n",
    "        return None\n",
    "    \n",
    "    obs = spectra_dict[(mzml, scan)]\n",
    "    obs_mz = np.array(obs['mz'])\n",
    "    obs_int = np.array(obs['intensity'])\n",
    "    psm_rec = psm_groups.get(spec_key, [])\n",
    "    \n",
    "    if len(obs_mz) == 0 or len(psm_rec) == 0:\n",
    "        return None\n",
    "    \n",
    "    prosit_list, psm_info = [], []\n",
    "    for r in psm_rec:\n",
    "        key = (r['Peptide'], int(r['Charge']))\n",
    "        if key in prosit_cache:\n",
    "            prosit_list.append({{'mz': prosit_cache[key]['mz'], 'int': prosit_cache[key]['intensity']}})\n",
    "            psm_info.append({{\n",
    "                'peptide': r['Peptide'], \n",
    "                'charge': int(r['Charge']),\n",
    "                'hyperscore': r['Hyperscore'], \n",
    "                'by_int_frac': r.get('by_int_frac', np.nan),\n",
    "                'ms1_intensity': r.get('ms1_combined', np.nan), \n",
    "                'prosit_cosine': r.get('prosit_cosine', np.nan)\n",
    "            }})\n",
    "    \n",
    "    if len(prosit_list) < CONFIG['MIN_PSMS']:\n",
    "        return None\n",
    "    \n",
    "    y, X, ch_mz = build_matrix_chimerys(obs_mz, obs_int, prosit_list, CONFIG['TOL_PPM'])\n",
    "    if y is None:\n",
    "        return None\n",
    "    \n",
    "    return {{\n",
    "        'spectrum_key': spec_key, \n",
    "        'y': y, \n",
    "        'X': X, \n",
    "        'channel_mz': ch_mz,\n",
    "        'psm_info': psm_info, \n",
    "        'n_psm': len(psm_info), \n",
    "        'n_channels': len(y)\n",
    "    }}\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print(f\"Processing with 32 workers\", flush=True)\n",
    "    \n",
    "    with Pool(32) as pool:\n",
    "        results = []\n",
    "        for i, res in enumerate(pool.imap_unordered(process, unique_chimeric, chunksize=200)):\n",
    "            if res:\n",
    "                results.append(res)\n",
    "            if (i + 1) % 20000 == 0:\n",
    "                print(f\"{{i+1:,}}/{{len(unique_chimeric):,}} | Built: {{len(results):,}}\", flush=True)\n",
    "    \n",
    "    print(f\"Total: {{len(results):,}} matrices\", flush=True)\n",
    "    \n",
    "    with open(\"{MATRIX_CACHE}\", 'wb') as f:\n",
    "        pickle.dump(results, f)\n",
    "    print(\"Saved\", flush=True)\n",
    "'''\n",
    "\n",
    "with open(PYTHON_SCRIPT, 'w') as f:\n",
    "    f.write(python_code)\n",
    "\n",
    "# SLURM script\n",
    "slurm_code = f'''#!/bin/bash\n",
    "#SBATCH --job-name=matrix_chimerys\n",
    "#SBATCH --ntasks=1\n",
    "#SBATCH --cpus-per-task=32\n",
    "#SBATCH --time=02:00:00\n",
    "#SBATCH --mem=50G\n",
    "#SBATCH --partition=zen2\n",
    "#SBATCH --output={CACHE_DIR}/matrix_chimerys_%j.out\n",
    "#SBATCH --error={CACHE_DIR}/matrix_chimerys_%j.err\n",
    "\n",
    "echo \"Started $(date)\"\n",
    "python {PYTHON_SCRIPT}\n",
    "echo \"Finished $(date)\"\n",
    "'''\n",
    "\n",
    "with open(SLURM_SCRIPT, 'w') as f:\n",
    "    f.write(slurm_code)\n",
    "\n",
    "# Remove old cache and submit\n",
    "if MATRIX_CACHE.exists():\n",
    "    MATRIX_CACHE.unlink()\n",
    "\n",
    "result = subprocess.run(['sbatch', str(SLURM_SCRIPT)], capture_output=True, text=True)\n",
    "if result.returncode == 0:\n",
    "    print(f\"Job {result.stdout.strip().split()[-1]} submitted\")\n",
    "else:\n",
    "    print(f\"Failed: {result.stderr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No job running\n",
      "\n",
      "=== matrix_chimerys_3027399.out ===\n",
      "Started Sun Jan 25 02:59:31 PM CET 2026\n",
      "Loaded 99,999 spectra\n",
      "Processing with 32 workers\n",
      "20,000/99,999 | Built: 19,982\n",
      "40,000/99,999 | Built: 39,972\n",
      "60,000/99,999 | Built: 59,972\n",
      "80,000/99,999 | Built: 79,971\n",
      "Total: 99,970 matrices\n",
      "Saved\n",
      "Finished Sun Jan 25 02:59:55 PM CET 2026\n",
      "\n",
      "✓ Results ready: 296.8 MB\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "CACHE_DIR = Path('/data/antwerpen/211/vsc21150/Exploring-Fragmentation-Competion-in-Proteomics-Data-to-Decode-Chimeric-Spectra/cache')\n",
    "MATRIX_CACHE = CACHE_DIR / 'spectra_data_chimerys.pkl'\n",
    "\n",
    "result = subprocess.run(['squeue', '-u', 'vsc21150', '-n', 'matrix_chimerys'], capture_output=True, text=True)\n",
    "print(result.stdout if result.stdout.strip().count('\\n') > 0 else \"No job running\")\n",
    "\n",
    "logs = sorted(CACHE_DIR.glob('matrix_chimerys_*.out'), key=lambda x: x.stat().st_mtime)\n",
    "if logs:\n",
    "    print(f\"\\n=== {logs[-1].name} ===\")\n",
    "    subprocess.run(['tail', '-15', str(logs[-1])])\n",
    "\n",
    "if MATRIX_CACHE.exists():\n",
    "    print(f\"\\n✓ Results ready: {MATRIX_CACHE.stat().st_size/1e6:.1f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 99,970 matrices\n",
      "PSMs: (array([2, 3, 4, 5]), array([33159, 34630, 22254,  9927]))\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "CACHE_DIR = Path('/data/antwerpen/211/vsc21150/Exploring-Fragmentation-Competion-in-Proteomics-Data-to-Decode-Chimeric-Spectra/cache')\n",
    "MATRIX_CACHE = CACHE_DIR / 'spectra_data_chimerys.pkl'\n",
    "\n",
    "with open(MATRIX_CACHE, 'rb') as f:\n",
    "    spectra_data = pickle.load(f)\n",
    "\n",
    "print(f\"Loaded {len(spectra_data):,} matrices\")\n",
    "print(f\"PSMs: {np.unique([sd['n_psm'] for sd in spectra_data], return_counts=True)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels: min=14, max=220, mean=57.6\n",
      "\n",
      "NNLS cosine (n=1000): 0.773 ± 0.193\n",
      "  >0.5: 88.6%\n",
      "  >0.7: 69.5%\n"
     ]
    }
   ],
   "source": [
    "# Quick validation\n",
    "n_ch = [sd['n_channels'] for sd in spectra_data]\n",
    "print(f\"Channels: min={min(n_ch)}, max={max(n_ch)}, mean={np.mean(n_ch):.1f}\")\n",
    "\n",
    "# Test NNLS on sample\n",
    "from scipy.optimize import nnls\n",
    "\n",
    "cosines = []\n",
    "for sd in spectra_data[:1000]:\n",
    "    y, X = sd['y'], sd['X']\n",
    "    beta, _ = nnls(X, y)\n",
    "    y_pred = X @ beta\n",
    "    cos = np.dot(y, y_pred) / (np.linalg.norm(y) * np.linalg.norm(y_pred) + 1e-10)\n",
    "    cosines.append(cos)\n",
    "\n",
    "print(f\"\\nNNLS cosine (n=1000): {np.mean(cosines):.3f} ± {np.std(cosines):.3f}\")\n",
    "print(f\"  >0.5: {100*np.mean(np.array(cosines) > 0.5):.1f}%\")\n",
    "print(f\"  >0.7: {100*np.mean(np.array(cosines) > 0.7):.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LASSO + ms1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "LASSO ANALYSIS: THREE MODELS\n",
      "======================================================================\n",
      "Model 1: LASSO (2+ PSM)\n",
      "Model 2: LASSO (3+ PSM)\n",
      "Model 3: LASSO+MS1 (3+ PSM)\n",
      "======================================================================\n",
      "\n",
      "Complete dataset (2+ PSM):\n",
      "  Total matrices: 99,970\n",
      "  Total PSMs:     308,859\n",
      "  Total spectra:  99,970\n",
      "\n",
      "PSM distribution:\n",
      "  2 PSM: 33,159 spectra\n",
      "  3 PSM: 34,630 spectra\n",
      "  4 PSM: 22,254 spectra\n",
      "  5 PSM: 9,927 spectra\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# LASSO ANALYSIS: DATASET PREPARATION\n",
    "# ============================================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.optimize import nnls\n",
    "from multiprocessing import Pool, cpu_count\n",
    "import time\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"LASSO ANALYSIS: THREE MODELS\")\n",
    "print(\"=\"*70)\n",
    "print(\"Model 1: LASSO (2+ PSM)\")\n",
    "print(\"Model 2: LASSO (3+ PSM)\")\n",
    "print(\"Model 3: LASSO+MS1 (3+ PSM)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Build PSM dataframe from spectra_data\n",
    "results_list = []\n",
    "for sd in spectra_data:\n",
    "    for j, psm in enumerate(sd['psm_info']):\n",
    "        results_list.append({\n",
    "            'spectrum_key': sd['spectrum_key'],\n",
    "            'peptide': psm['peptide'],\n",
    "            'charge': psm['charge'],\n",
    "            'hyperscore': psm['hyperscore'],\n",
    "            'by_int_frac': psm.get('by_int_frac', np.nan),\n",
    "            'prosit_cosine': psm.get('prosit_cosine', np.nan),\n",
    "            'ms1_intensity': psm.get('ms1_intensity', 0),\n",
    "            'n_psm': sd['n_psm']\n",
    "        })\n",
    "\n",
    "df_results_all = pd.DataFrame(results_list)\n",
    "\n",
    "print(f\"\\nComplete dataset (2+ PSM):\")\n",
    "print(f\"  Total matrices: {len(spectra_data):,}\")\n",
    "print(f\"  Total PSMs:     {len(df_results_all):,}\")\n",
    "print(f\"  Total spectra:  {df_results_all['spectrum_key'].nunique():,}\")\n",
    "\n",
    "# PSM distribution\n",
    "psm_dist = df_results_all.groupby('spectrum_key')['n_psm'].first().value_counts().sort_index()\n",
    "print(f\"\\nPSM distribution:\")\n",
    "for n, count in psm_dist.items():\n",
    "    print(f\"  {n} PSM: {count:,} spectra\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "MS1 DATA INTEGRATION\n",
      "======================================================================\n",
      "\n",
      "Loading MS1 data from psm_clean.csv...\n",
      "  Loaded: 1,276,641 rows\n",
      "  After merge: 308,891 PSMs\n",
      "  PSMs with MS1 > 0: 280,214\n",
      "\n",
      "Filtering to spectra with complete MS1 (for LASSO+MS1 model)...\n",
      "  Spectra with complete MS1: 79,396\n",
      "  PSMs with complete MS1: 240,907\n",
      "\n",
      "  PSM distribution (MS1 complete):\n",
      "    2 PSM: 28,209 spectra (35.5%)\n",
      "    3 PSM: 27,449 spectra (34.6%)\n",
      "    4 PSM: 16,572 spectra (20.9%)\n",
      "    5 PSM: 7,166 spectra (9.0%)\n",
      "\n",
      "Building MS1 lookup dictionary...\n",
      "  MS1 entries: 240,871\n",
      "\n",
      "======================================================================\n",
      "DATASET SUMMARY\n",
      "======================================================================\n",
      "\n",
      "Original dataset (2+ PSM):\n",
      "  Total spectra:    99,970\n",
      "  Total PSMs:       308,891\n",
      "\n",
      "Filtered dataset (MS1 complete, for Model 3):\n",
      "  Total spectra:    79,396\n",
      "  Total PSMs:       240,907\n",
      "  Coverage:         79.4%\n",
      "\n",
      "======================================================================\n",
      "✓ MS1 data ready\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# MERGE WITH MS1 DATA FROM psm_clean.csv\n",
    "# ============================================================\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"MS1 DATA INTEGRATION\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "print(f\"\\nLoading MS1 data from psm_clean.csv...\")\n",
    "df_clean = pd.read_csv(DATA_DIR / 'psm_clean.csv', \n",
    "                       usecols=['spectrum_key', 'Peptide', 'Intensity'])\n",
    "df_clean = df_clean.rename(columns={'Peptide': 'peptide', 'Intensity': 'ms1_intensity'})\n",
    "print(f\"  Loaded: {len(df_clean):,} rows\")\n",
    "\n",
    "# Merge\n",
    "df_results_all = df_results_all.drop(columns=['ms1_intensity'], errors='ignore')\n",
    "df_results_all = df_results_all.merge(\n",
    "    df_clean[['spectrum_key', 'peptide', 'ms1_intensity']],\n",
    "    on=['spectrum_key', 'peptide'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "print(f\"  After merge: {len(df_results_all):,} PSMs\")\n",
    "print(f\"  PSMs with MS1 > 0: {(df_results_all['ms1_intensity'] > 0).sum():,}\")\n",
    "\n",
    "# Filter to spectra with complete MS1 (for LASSO+MS1 model only)\n",
    "def has_complete_ms1(group):\n",
    "    \"\"\"Check if all peptides in spectrum have MS1 > 0\"\"\"\n",
    "    return (group['ms1_intensity'] > 0).all()\n",
    "\n",
    "print(f\"\\nFiltering to spectra with complete MS1 (for LASSO+MS1 model)...\")\n",
    "spectra_with_ms1 = df_results_all.groupby('spectrum_key').filter(has_complete_ms1)\n",
    "unique_spectra_ms1 = spectra_with_ms1['spectrum_key'].unique()\n",
    "unique_spectra_ms1_set = set(unique_spectra_ms1)\n",
    "\n",
    "print(f\"  Spectra with complete MS1: {len(unique_spectra_ms1):,}\")\n",
    "print(f\"  PSMs with complete MS1: {len(spectra_with_ms1):,}\")\n",
    "\n",
    "# PSM distribution for MS1-complete spectra\n",
    "psm_dist_ms1 = spectra_with_ms1.groupby('spectrum_key')['n_psm'].first().value_counts().sort_index()\n",
    "print(f\"\\n  PSM distribution (MS1 complete):\")\n",
    "for n, count in psm_dist_ms1.items():\n",
    "    print(f\"    {n} PSM: {count:,} spectra ({100*count/len(unique_spectra_ms1):.1f}%)\")\n",
    "\n",
    "# Build MS1 lookup dictionary (for LASSO+MS1 model)\n",
    "print(f\"\\nBuilding MS1 lookup dictionary...\")\n",
    "ms1_dict = {}\n",
    "for _, row in spectra_with_ms1.iterrows():\n",
    "    key = (row['spectrum_key'], row['peptide'])\n",
    "    ms1_dict[key] = row['ms1_intensity']\n",
    "\n",
    "print(f\"  MS1 entries: {len(ms1_dict):,}\")\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"DATASET SUMMARY\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "print(f\"\\nOriginal dataset (2+ PSM):\")\n",
    "print(f\"  Total spectra:    {len(spectra_data):,}\")\n",
    "print(f\"  Total PSMs:       {len(df_results_all):,}\")\n",
    "\n",
    "print(f\"\\nFiltered dataset (MS1 complete, for Model 3):\")\n",
    "print(f\"  Total spectra:    {len(unique_spectra_ms1):,}\")\n",
    "print(f\"  Total PSMs:       {len(spectra_with_ms1):,}\")\n",
    "print(f\"  Coverage:         {100*len(unique_spectra_ms1)/len(spectra_data):.1f}%\")\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"✓ MS1 data ready\")\n",
    "print(f\"{'='*70}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "PREPARING DATASETS FOR THREE MODELS\n",
      "======================================================================\n",
      "\n",
      "Model 1: LASSO (2+ PSM)\n",
      "  Spectra: 99,970\n",
      "\n",
      "Model 2: LASSO (3+ PSM)\n",
      "  Spectra: 66,811\n",
      "\n",
      "Model 3: LASSO+MS1 (3+ PSM)\n",
      "  Filtering to 3+ PSM with complete MS1...\n",
      "  Adding MS1 to design matrices...\n",
      "  Augmented matrices: 51,187\n",
      "  Skipped: 0\n",
      "\n",
      "======================================================================\n",
      "TRAIN/VALIDATION SPLITS\n",
      "======================================================================\n",
      "\n",
      "Model 1: LASSO (2+ PSM)\n",
      "  Train: 69,979\n",
      "  Val:   29,991\n",
      "\n",
      "Model 2: LASSO (3+ PSM)\n",
      "  Train: 46,767\n",
      "  Val:   20,044\n",
      "\n",
      "Model 3: LASSO+MS1 (3+ PSM)\n",
      "  Train: 35,830\n",
      "  Val:   15,357\n",
      "\n",
      "======================================================================\n",
      "✓ All datasets prepared\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# PREPARE DATASETS FOR THREE MODELS\n",
    "# ============================================================\n",
    "\n",
    "def add_ms1_to_matrix(sd, ms1_dict):\n",
    "    \"\"\"\n",
    "    Add MS1 as additional features to design matrix.\n",
    "    Strategy: Add MS1 as \"soft prior\" channels\n",
    "    Each peptide gets a diagonal row with its normalized MS1\n",
    "    \"\"\"\n",
    "    spec_key = sd['spectrum_key']\n",
    "    X = sd['X']\n",
    "    n_channels, n_pep = X.shape\n",
    "    \n",
    "    # Extract MS1 for each peptide\n",
    "    ms1_values = []\n",
    "    for psm in sd['psm_info']:\n",
    "        peptide = psm['peptide']\n",
    "        ms1 = ms1_dict.get((spec_key, peptide), 0)\n",
    "        ms1_values.append(ms1)\n",
    "    \n",
    "    ms1_values = np.array(ms1_values)\n",
    "    \n",
    "    # Skip if any MS1 missing or zero\n",
    "    if (ms1_values <= 0).any():\n",
    "        return None\n",
    "    \n",
    "    # Normalize MS1 to sum = 1\n",
    "    ms1_norm = ms1_values / ms1_values.sum()\n",
    "    \n",
    "    # Augment design matrix\n",
    "    ms1_channels = np.diag(ms1_norm)\n",
    "    X_augmented = np.vstack([X, ms1_channels])\n",
    "    y_augmented = np.concatenate([sd['y'], np.zeros(n_pep)])\n",
    "    \n",
    "    return {\n",
    "        'spectrum_key': spec_key,\n",
    "        'y': sd['y'],\n",
    "        'y_augmented': y_augmented,\n",
    "        'X_base': X,\n",
    "        'X_augmented': X_augmented,\n",
    "        'ms1_values': ms1_values,\n",
    "        'ms1_norm': ms1_norm,\n",
    "        'psm_info': sd['psm_info'],\n",
    "        'n_psm': sd['n_psm'],\n",
    "        'n_channels': n_channels\n",
    "    }\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"PREPARING DATASETS FOR THREE MODELS\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "# Model 1: LASSO (2+ PSM) - uses all spectra as-is\n",
    "spectra_2plus = spectra_data.copy()\n",
    "print(f\"\\nModel 1: LASSO (2+ PSM)\")\n",
    "print(f\"  Spectra: {len(spectra_2plus):,}\")\n",
    "\n",
    "# Model 2: LASSO (3+ PSM) - filter to 3+ PSM only\n",
    "spectra_3plus = [sd for sd in spectra_data if sd['n_psm'] >= 3]\n",
    "print(f\"\\nModel 2: LASSO (3+ PSM)\")\n",
    "print(f\"  Spectra: {len(spectra_3plus):,}\")\n",
    "\n",
    "# Model 3: LASSO+MS1 (3+ PSM) - filter to 3+ PSM with complete MS1, then augment\n",
    "print(f\"\\nModel 3: LASSO+MS1 (3+ PSM)\")\n",
    "print(f\"  Filtering to 3+ PSM with complete MS1...\")\n",
    "spectra_3plus_ms1_temp = [sd for sd in spectra_data \n",
    "                          if sd['n_psm'] >= 3 and sd['spectrum_key'] in unique_spectra_ms1_set]\n",
    "\n",
    "print(f\"  Adding MS1 to design matrices...\")\n",
    "spectra_3plus_ms1 = []\n",
    "skipped = 0\n",
    "\n",
    "for sd in spectra_3plus_ms1_temp:\n",
    "    result = add_ms1_to_matrix(sd, ms1_dict)\n",
    "    if result is not None:\n",
    "        spectra_3plus_ms1.append(result)\n",
    "    else:\n",
    "        skipped += 1\n",
    "\n",
    "print(f\"  Augmented matrices: {len(spectra_3plus_ms1):,}\")\n",
    "print(f\"  Skipped: {skipped:,}\")\n",
    "\n",
    "# Train/val splits for all three models\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"TRAIN/VALIDATION SPLITS\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "# Model 1: LASSO (2+ PSM)\n",
    "indices_2plus = list(range(len(spectra_2plus)))\n",
    "train_idx_2plus, val_idx_2plus = train_test_split(indices_2plus, test_size=0.3, random_state=42)\n",
    "train_2plus = [spectra_2plus[i] for i in train_idx_2plus]\n",
    "val_2plus = [spectra_2plus[i] for i in val_idx_2plus]\n",
    "\n",
    "print(f\"\\nModel 1: LASSO (2+ PSM)\")\n",
    "print(f\"  Train: {len(train_2plus):,}\")\n",
    "print(f\"  Val:   {len(val_2plus):,}\")\n",
    "\n",
    "# Model 2: LASSO (3+ PSM)\n",
    "indices_3plus = list(range(len(spectra_3plus)))\n",
    "train_idx_3plus, val_idx_3plus = train_test_split(indices_3plus, test_size=0.3, random_state=42)\n",
    "train_3plus = [spectra_3plus[i] for i in train_idx_3plus]\n",
    "val_3plus = [spectra_3plus[i] for i in val_idx_3plus]\n",
    "\n",
    "print(f\"\\nModel 2: LASSO (3+ PSM)\")\n",
    "print(f\"  Train: {len(train_3plus):,}\")\n",
    "print(f\"  Val:   {len(val_3plus):,}\")\n",
    "\n",
    "# Model 3: LASSO+MS1 (3+ PSM)\n",
    "indices_3plus_ms1 = list(range(len(spectra_3plus_ms1)))\n",
    "train_idx_3plus_ms1, val_idx_3plus_ms1 = train_test_split(indices_3plus_ms1, test_size=0.3, random_state=42)\n",
    "train_3plus_ms1 = [spectra_3plus_ms1[i] for i in train_idx_3plus_ms1]\n",
    "val_3plus_ms1 = [spectra_3plus_ms1[i] for i in val_idx_3plus_ms1]\n",
    "\n",
    "print(f\"\\nModel 3: LASSO+MS1 (3+ PSM)\")\n",
    "print(f\"  Train: {len(train_3plus_ms1):,}\")\n",
    "print(f\"  Val:   {len(val_3plus_ms1):,}\")\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"✓ All datasets prepared\")\n",
    "print(f\"{'='*70}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "LAMBDA GRID SEARCH\n",
      "======================================================================\n",
      "\n",
      "Grid: 8 values\n",
      "\n",
      "--- Model 1: LASSO (2+ PSM) ---\n",
      "Training spectra: 69,979\n",
      "  λ=    NNLS: cosine=0.7942, k=3.1, time=6.2s\n",
      "  λ=   1e-08: cosine=0.7942, k=3.1, time=7.5s\n",
      "  λ=   1e-07: cosine=0.7942, k=3.1, time=8.3s\n",
      "  λ=   1e-06: cosine=0.7942, k=3.1, time=10.2s\n",
      "  λ=   1e-05: cosine=0.7942, k=3.1, time=8.2s\n",
      "  λ=   1e-04: cosine=0.7897, k=2.8, time=7.8s\n",
      "  λ=   1e-03: cosine=0.5197, k=0.9, time=8.5s\n",
      "  λ=   1e-02: cosine=0.0058, k=0.0, time=8.4s\n",
      "\n",
      "--- Model 2: LASSO (3+ PSM) ---\n",
      "Training spectra: 46,767\n",
      "  λ=    NNLS: cosine=0.8024, k=3.6, time=7.8s\n",
      "  λ=   1e-08: cosine=0.8024, k=3.6, time=7.6s\n",
      "  λ=   1e-07: cosine=0.8024, k=3.6, time=8.4s\n",
      "  λ=   1e-06: cosine=0.8024, k=3.6, time=7.6s\n",
      "  λ=   1e-05: cosine=0.8023, k=3.6, time=7.9s\n",
      "  λ=   1e-04: cosine=0.7957, k=3.2, time=8.3s\n",
      "  λ=   1e-03: cosine=0.4227, k=0.7, time=8.8s\n",
      "  λ=   1e-02: cosine=0.0001, k=0.0, time=8.8s\n",
      "\n",
      "--- Model 3: LASSO+MS1 (3+ PSM) ---\n",
      "Training spectra: 35,830\n",
      "  λ=    NNLS: cosine=0.7462, k=3.6, time=8.6s\n",
      "  λ=   1e-08: cosine=0.7462, k=3.6, time=8.9s\n",
      "  λ=   1e-07: cosine=0.7462, k=3.6, time=8.7s\n",
      "  λ=   1e-06: cosine=0.7464, k=3.6, time=9.0s\n",
      "  λ=   1e-05: cosine=0.7483, k=3.6, time=9.3s\n",
      "  λ=   1e-04: cosine=0.7583, k=3.2, time=9.4s\n",
      "  λ=   1e-03: cosine=0.4009, k=0.7, time=9.1s\n",
      "  λ=   1e-02: cosine=0.0000, k=0.0, time=8.2s\n",
      "\n",
      "✓ Grid search complete for all three models\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# LAMBDA GRID SEARCH: THREE MODELS\n",
    "# ============================================================\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "def cosine(a, b):\n",
    "    n = np.linalg.norm(a) * np.linalg.norm(b)\n",
    "    return np.dot(a, b) / n if n > 1e-10 else 0.0\n",
    "\n",
    "def evaluate_lasso(args):\n",
    "    sd, use_ms1, lambda_val, model_name = args\n",
    "    \n",
    "    if use_ms1:\n",
    "        X = sd['X_augmented']\n",
    "        y = sd['y_augmented']\n",
    "        X_base = sd['X_base']\n",
    "        y_base = sd['y']\n",
    "    else:\n",
    "        X = sd['X']\n",
    "        y = sd['y']\n",
    "        X_base = X\n",
    "        y_base = y\n",
    "    \n",
    "    # Fit LASSO\n",
    "    if lambda_val == 0:\n",
    "        beta, _ = nnls(X, y)\n",
    "    else:\n",
    "        model = Lasso(alpha=lambda_val, positive=True,\n",
    "                     fit_intercept=False, max_iter=10000, tol=1e-8)\n",
    "        model.fit(X, y)\n",
    "        beta = model.coef_\n",
    "    \n",
    "    # Predict on spectral part\n",
    "    y_pred = X_base @ beta[:sd['n_psm']]\n",
    "    cos = cosine(y_base, y_pred)\n",
    "    \n",
    "    # Sparsity\n",
    "    k = np.sum(beta[:sd['n_psm']] > 1e-6)\n",
    "    \n",
    "    return {\n",
    "        'spectrum_key': sd['spectrum_key'],\n",
    "        'model': model_name,\n",
    "        'lambda': lambda_val,\n",
    "        'cosine': cos,\n",
    "        'k': k,\n",
    "        'n_psm': sd['n_psm']\n",
    "    }\n",
    "\n",
    "# Lambda grid\n",
    "LAMBDA_GRID = np.array([0, 1e-8, 1e-7, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2])\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"LAMBDA GRID SEARCH\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"\\nGrid: {len(LAMBDA_GRID)} values\")\n",
    "\n",
    "all_results = []\n",
    "\n",
    "# Model 1: LASSO (2+ PSM)\n",
    "print(f\"\\n--- Model 1: LASSO (2+ PSM) ---\")\n",
    "print(f\"Training spectra: {len(train_2plus):,}\")\n",
    "\n",
    "for lam in LAMBDA_GRID:\n",
    "    tasks = [(sd, False, lam, 'LASSO (2+ PSM)') for sd in train_2plus]\n",
    "    \n",
    "    t0 = time.time()\n",
    "    with Pool(cpu_count()) as pool:\n",
    "        results = pool.map(evaluate_lasso, tasks, chunksize=200)\n",
    "    t1 = time.time()\n",
    "    \n",
    "    all_results.extend(results)\n",
    "    \n",
    "    mean_cos = np.mean([r['cosine'] for r in results])\n",
    "    mean_k = np.mean([r['k'] for r in results])\n",
    "    lam_str = \"NNLS\" if lam == 0 else f\"{lam:.0e}\"\n",
    "    \n",
    "    print(f\"  λ={lam_str:>8s}: cosine={mean_cos:.4f}, k={mean_k:.1f}, time={t1-t0:.1f}s\")\n",
    "\n",
    "# Model 2: LASSO (3+ PSM)\n",
    "print(f\"\\n--- Model 2: LASSO (3+ PSM) ---\")\n",
    "print(f\"Training spectra: {len(train_3plus):,}\")\n",
    "\n",
    "for lam in LAMBDA_GRID:\n",
    "    tasks = [(sd, False, lam, 'LASSO (3+ PSM)') for sd in train_3plus]\n",
    "    \n",
    "    t0 = time.time()\n",
    "    with Pool(cpu_count()) as pool:\n",
    "        results = pool.map(evaluate_lasso, tasks, chunksize=200)\n",
    "    t1 = time.time()\n",
    "    \n",
    "    all_results.extend(results)\n",
    "    \n",
    "    mean_cos = np.mean([r['cosine'] for r in results])\n",
    "    mean_k = np.mean([r['k'] for r in results])\n",
    "    lam_str = \"NNLS\" if lam == 0 else f\"{lam:.0e}\"\n",
    "    \n",
    "    print(f\"  λ={lam_str:>8s}: cosine={mean_cos:.4f}, k={mean_k:.1f}, time={t1-t0:.1f}s\")\n",
    "\n",
    "# Model 3: LASSO+MS1 (3+ PSM)\n",
    "print(f\"\\n--- Model 3: LASSO+MS1 (3+ PSM) ---\")\n",
    "print(f\"Training spectra: {len(train_3plus_ms1):,}\")\n",
    "\n",
    "for lam in LAMBDA_GRID:\n",
    "    tasks = [(sd, True, lam, 'LASSO+MS1 (3+ PSM)') for sd in train_3plus_ms1]\n",
    "    \n",
    "    t0 = time.time()\n",
    "    with Pool(cpu_count()) as pool:\n",
    "        results = pool.map(evaluate_lasso, tasks, chunksize=200)\n",
    "    t1 = time.time()\n",
    "    \n",
    "    all_results.extend(results)\n",
    "    \n",
    "    mean_cos = np.mean([r['cosine'] for r in results])\n",
    "    mean_k = np.mean([r['k'] for r in results])\n",
    "    lam_str = \"NNLS\" if lam == 0 else f\"{lam:.0e}\"\n",
    "    \n",
    "    print(f\"  λ={lam_str:>8s}: cosine={mean_cos:.4f}, k={mean_k:.1f}, time={t1-t0:.1f}s\")\n",
    "\n",
    "df_grid = pd.DataFrame(all_results)\n",
    "print(f\"\\n✓ Grid search complete for all three models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "OPTIMAL LAMBDA SELECTION\n",
      "======================================================================\n",
      "\n",
      "Model                              λ   Cosine      Std      k\n",
      "----------------------------------------------------------------------\n",
      "LASSO (2+ PSM)                  NNLS   0.7942   0.1657    3.1\n",
      "LASSO (2+ PSM)                 1e-08   0.7942   0.1657    3.1\n",
      "LASSO (2+ PSM)                 1e-07   0.7942   0.1657    3.1\n",
      "LASSO (2+ PSM)                 1e-06   0.7942   0.1657    3.1\n",
      "LASSO (2+ PSM)                 1e-05   0.7942   0.1657    3.1\n",
      "LASSO (2+ PSM)                 1e-04   0.7897   0.1658    2.8\n",
      "LASSO (2+ PSM)                 1e-03   0.5197   0.3869    0.9\n",
      "LASSO (2+ PSM)                 1e-02   0.0058   0.0735    0.0\n",
      "LASSO (3+ PSM)                  NNLS   0.8024   0.1507    3.6\n",
      "LASSO (3+ PSM)                 1e-08   0.8024   0.1507    3.6\n",
      "LASSO (3+ PSM)                 1e-07   0.8024   0.1507    3.6\n",
      "LASSO (3+ PSM)                 1e-06   0.8024   0.1507    3.6\n",
      "LASSO (3+ PSM)                 1e-05   0.8023   0.1507    3.6\n",
      "LASSO (3+ PSM)                 1e-04   0.7957   0.1512    3.2\n",
      "LASSO (3+ PSM)                 1e-03   0.4227   0.4007    0.7\n",
      "LASSO (3+ PSM)                 1e-02   0.0001   0.0077    0.0\n",
      "LASSO+MS1 (3+ PSM)              NNLS   0.7462   0.1523    3.6\n",
      "LASSO+MS1 (3+ PSM)             1e-08   0.7462   0.1523    3.6\n",
      "LASSO+MS1 (3+ PSM)             1e-07   0.7462   0.1523    3.6\n",
      "LASSO+MS1 (3+ PSM)             1e-06   0.7464   0.1523    3.6\n",
      "LASSO+MS1 (3+ PSM)             1e-05   0.7483   0.1525    3.6\n",
      "LASSO+MS1 (3+ PSM)             1e-04   0.7583   0.1542    3.2\n",
      "LASSO+MS1 (3+ PSM)             1e-03   0.4009   0.4021    0.7\n",
      "LASSO+MS1 (3+ PSM)             1e-02   0.0000   0.0000    0.0\n",
      "\n",
      "======================================================================\n",
      "OPTIMAL LAMBDAS\n",
      "======================================================================\n",
      "\n",
      "LASSO (2+ PSM):\n",
      "  λ*:     NNLS (0)\n",
      "  Cosine: 0.7942\n",
      "  k:      3.1\n",
      "\n",
      "LASSO (3+ PSM):\n",
      "  λ*:     NNLS (0)\n",
      "  Cosine: 0.8024\n",
      "  k:      3.6\n",
      "\n",
      "LASSO+MS1 (3+ PSM):\n",
      "  λ*:     1e-04\n",
      "  Cosine: 0.7583\n",
      "  k:      3.2\n",
      "\n",
      "======================================================================\n",
      "✓ Optimal lambdas selected\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# SELECT OPTIMAL LAMBDA\n",
    "# ============================================================\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"OPTIMAL LAMBDA SELECTION\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "# Aggregate by model and lambda\n",
    "summary = df_grid.groupby(['model', 'lambda']).agg({\n",
    "    'cosine': ['mean', 'std'],\n",
    "    'k': 'mean'\n",
    "}).round(4)\n",
    "\n",
    "summary.columns = ['Cosine_Mean', 'Cosine_Std', 'k_Mean']\n",
    "\n",
    "print(f\"\\n{'Model':25s} {'λ':>10s} {'Cosine':>8s} {'Std':>8s} {'k':>6s}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for (model, lam), row in summary.iterrows():\n",
    "    lam_str = \"NNLS\" if lam == 0 else f\"{lam:.0e}\"\n",
    "    print(f\"{model:25s} {lam_str:>10s} {row['Cosine_Mean']:>8.4f} \"\n",
    "          f\"{row['Cosine_Std']:>8.4f} {row['k_Mean']:>6.1f}\")\n",
    "\n",
    "# Find optimal lambda for each model\n",
    "optimal = {}\n",
    "for model in ['LASSO (2+ PSM)', 'LASSO (3+ PSM)', 'LASSO+MS1 (3+ PSM)']:\n",
    "    subset = summary.loc[model]\n",
    "    valid = subset[subset['k_Mean'] > 0]\n",
    "    if len(valid) > 0:\n",
    "        best_lam = valid['Cosine_Mean'].idxmax()\n",
    "        optimal[model] = best_lam\n",
    "    else:\n",
    "        optimal[model] = 0\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"OPTIMAL LAMBDAS\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "for model, lam in optimal.items():\n",
    "    lam_str = \"NNLS (0)\" if lam == 0 else f\"{lam:.0e}\"\n",
    "    cos_mean = summary.loc[(model, lam), 'Cosine_Mean']\n",
    "    k_mean = summary.loc[(model, lam), 'k_Mean']\n",
    "    print(f\"\\n{model}:\")\n",
    "    print(f\"  λ*:     {lam_str}\")\n",
    "    print(f\"  Cosine: {cos_mean:.4f}\")\n",
    "    print(f\"  k:      {k_mean:.1f}\")\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"✓ Optimal lambdas selected\")\n",
    "print(f\"{'='*70}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "REGULARIZATION PATH ANALYSIS\n",
      "======================================================================\n",
      "\n",
      "Sampling 10 spectra per model (for visualization)\n",
      "Lambda grid: 30 points\n",
      "\n",
      "Computing paths...\n",
      "✓ Paths computed for 10 spectra per model\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# REGULARIZATION PATH ANALYSIS (VISUAL ONLY - SMALL SAMPLE)\n",
    "# ============================================================\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import Lasso\n",
    "from scipy.optimize import nnls\n",
    "import time\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"REGULARIZATION PATH ANALYSIS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Small sample for visualization only\n",
    "SAMPLE_SIZE = 10\n",
    "LAMBDA_PATH = np.logspace(-8, 0, 30)\n",
    "\n",
    "print(f\"\\nSampling {SAMPLE_SIZE} spectra per model (for visualization)\")\n",
    "print(f\"Lambda grid: {len(LAMBDA_PATH)} points\")\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# Sample from each training set\n",
    "sample_2plus = np.random.choice(train_2plus, min(SAMPLE_SIZE, len(train_2plus)), replace=False)\n",
    "sample_3plus = np.random.choice(train_3plus, min(SAMPLE_SIZE, len(train_3plus)), replace=False)\n",
    "sample_3plus_ms1 = np.random.choice(train_3plus_ms1, min(SAMPLE_SIZE, len(train_3plus_ms1)), replace=False)\n",
    "\n",
    "# ============================================================\n",
    "# COMPUTE PATHS\n",
    "# ============================================================\n",
    "\n",
    "def compute_path(sd, lambdas, use_ms1):\n",
    "    \"\"\"Compute LASSO path for one spectrum\"\"\"\n",
    "    if use_ms1:\n",
    "        X = sd['X_augmented']\n",
    "        y = sd['y_augmented']\n",
    "        X_base = sd['X_base']\n",
    "        y_base = sd['y']\n",
    "    else:\n",
    "        X = sd['X']\n",
    "        y = sd['y']\n",
    "        X_base = X\n",
    "        y_base = y\n",
    "    \n",
    "    n_pep = sd['n_psm']\n",
    "    cosines = []\n",
    "    k_ratios = []\n",
    "    \n",
    "    for lam in lambdas:\n",
    "        if lam == 0:\n",
    "            beta, _ = nnls(X, y)\n",
    "        else:\n",
    "            model = Lasso(alpha=lam, positive=True, fit_intercept=False, \n",
    "                         max_iter=10000, tol=1e-8)\n",
    "            model.fit(X, y)\n",
    "            beta = model.coef_\n",
    "        \n",
    "        beta_pep = beta[:n_pep]\n",
    "        y_pred = X_base @ beta_pep\n",
    "        cos = np.dot(y_base, y_pred) / (np.linalg.norm(y_base) * \n",
    "                                         np.linalg.norm(y_pred) + 1e-10)\n",
    "        cosines.append(cos)\n",
    "        k_ratios.append(np.sum(beta_pep > 1e-6) / n_pep)\n",
    "    \n",
    "    return np.array(cosines), np.array(k_ratios)\n",
    "\n",
    "# Compute paths for all three models\n",
    "print(\"\\nComputing paths...\")\n",
    "\n",
    "cosines_2plus_list = []\n",
    "k_2plus_list = []\n",
    "for sd in sample_2plus:\n",
    "    cos, k = compute_path(sd, LAMBDA_PATH, use_ms1=False)\n",
    "    cosines_2plus_list.append(cos)\n",
    "    k_2plus_list.append(k)\n",
    "\n",
    "cosines_3plus_list = []\n",
    "k_3plus_list = []\n",
    "for sd in sample_3plus:\n",
    "    cos, k = compute_path(sd, LAMBDA_PATH, use_ms1=False)\n",
    "    cosines_3plus_list.append(cos)\n",
    "    k_3plus_list.append(k)\n",
    "\n",
    "cosines_3plus_ms1_list = []\n",
    "k_3plus_ms1_list = []\n",
    "for sd in sample_3plus_ms1:\n",
    "    cos, k = compute_path(sd, LAMBDA_PATH, use_ms1=True)\n",
    "    cosines_3plus_ms1_list.append(cos)\n",
    "    k_3plus_ms1_list.append(k)\n",
    "\n",
    "# Aggregate\n",
    "cos_mean_2plus = np.mean(cosines_2plus_list, axis=0)\n",
    "cos_mean_3plus = np.mean(cosines_3plus_list, axis=0)\n",
    "cos_mean_3plus_ms1 = np.mean(cosines_3plus_ms1_list, axis=0)\n",
    "\n",
    "k_mean_2plus = np.mean(k_2plus_list, axis=0)\n",
    "k_mean_3plus = np.mean(k_3plus_list, axis=0)\n",
    "k_mean_3plus_ms1 = np.mean(k_3plus_ms1_list, axis=0)\n",
    "\n",
    "print(f\"✓ Paths computed for {SAMPLE_SIZE} spectra per model\")\n",
    "\n",
    "FIG_DIR = Path('/tmp/lasso_figures')\n",
    "FIG_DIR.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 960x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Saved: /tmp/lasso_figures/performance_at_optimal_lambda.png\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# FIGURE: PERFORMANCE AT OPTIMAL LAMBDA\n",
    "# ============================================================\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 6))\n",
    "\n",
    "COLOR_2PLUS = '#E63946'\n",
    "COLOR_3PLUS = '#F77F00'\n",
    "COLOR_MS1 = '#457B9D'\n",
    "\n",
    "# Optimal lambdas\n",
    "lam_opt_2plus = optimal['LASSO (2+ PSM)']\n",
    "lam_opt_3plus = optimal['LASSO (3+ PSM)']\n",
    "lam_opt_ms1 = optimal['LASSO+MS1 (3+ PSM)']\n",
    "\n",
    "# Extract performance at optimal lambdas\n",
    "idx_2plus = np.argmin(np.abs(LAMBDA_PATH - (lam_opt_2plus if lam_opt_2plus > 0 else LAMBDA_PATH[0])))\n",
    "idx_3plus = np.argmin(np.abs(LAMBDA_PATH - (lam_opt_3plus if lam_opt_3plus > 0 else LAMBDA_PATH[0])))\n",
    "idx_ms1 = np.argmin(np.abs(LAMBDA_PATH - (lam_opt_ms1 if lam_opt_ms1 > 0 else LAMBDA_PATH[0])))\n",
    "\n",
    "models = ['LASSO\\n(2+ PSM)', 'LASSO\\n(3+ PSM)', 'LASSO+MS1\\n(3+ PSM)']\n",
    "cosines_at_opt = [cos_mean_2plus[idx_2plus], cos_mean_3plus[idx_3plus], cos_mean_3plus_ms1[idx_ms1]]\n",
    "colors = [COLOR_2PLUS, COLOR_3PLUS, COLOR_MS1]\n",
    "\n",
    "bars = ax.bar(models, cosines_at_opt, color=colors, alpha=0.7, edgecolor='black', linewidth=2)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, val in zip(bars, cosines_at_opt):\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "            f'{val:.4f}',\n",
    "            ha='center', va='bottom', fontweight='bold', fontsize=11)\n",
    "\n",
    "ax.set_ylabel('Mean Cosine', fontweight='bold', fontsize=12)\n",
    "ax.set_title('Performance at Optimal λ', fontweight='bold', fontsize=13)\n",
    "ax.grid(alpha=0.3, axis='y')\n",
    "ax.set_ylim([0, max(cosines_at_opt) * 1.1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIG_DIR / 'performance_at_optimal_lambda.png', dpi=150, facecolor='white')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n✓ Saved: {FIG_DIR / 'performance_at_optimal_lambda.png'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 2160x600 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Saved: /tmp/lasso_figures/regularization_paths_three_models.png\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# FIGURE: REGULARIZATION PATHS - ONE PLOT PER MODEL\n",
    "# ============================================================\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "COLOR_2PLUS = '#E63946'\n",
    "COLOR_3PLUS = '#F77F00'\n",
    "COLOR_MS1 = '#457B9D'\n",
    "\n",
    "# Optimal lambdas\n",
    "lam_opt_2plus = optimal['LASSO (2+ PSM)']\n",
    "lam_opt_3plus = optimal['LASSO (3+ PSM)']\n",
    "lam_opt_ms1 = optimal['LASSO+MS1 (3+ PSM)']\n",
    "\n",
    "# ============================================================\n",
    "# Panel 1: LASSO (2+ PSM)\n",
    "# ============================================================\n",
    "ax = axes[0]\n",
    "\n",
    "# Individual paths\n",
    "for i, cos_path in enumerate(cosines_2plus_list):\n",
    "    ax.plot(LAMBDA_PATH, cos_path, linewidth=1.5, alpha=0.5, color=COLOR_2PLUS)\n",
    "\n",
    "# Mean path\n",
    "ax.plot(LAMBDA_PATH, cos_mean_2plus, linewidth=3, color='black', \n",
    "       label='Mean', zorder=10, linestyle='--')\n",
    "\n",
    "# Optimal lambda\n",
    "if lam_opt_2plus > 0:\n",
    "    ax.axvline(lam_opt_2plus, color=COLOR_2PLUS, linestyle='--', \n",
    "              linewidth=2.5, alpha=0.8, label=f'Optimal λ = {lam_opt_2plus:.0e}')\n",
    "else:\n",
    "    ax.axvline(LAMBDA_PATH[0], color=COLOR_2PLUS, linestyle='--', \n",
    "              linewidth=2.5, alpha=0.8, label='Optimal λ = NNLS')\n",
    "\n",
    "ax.set_xscale('log')\n",
    "ax.set_xlabel('λ (Regularization Parameter)', fontweight='bold', fontsize=11)\n",
    "ax.set_ylabel('Reconstruction Cosine', fontweight='bold', fontsize=11)\n",
    "ax.set_title(f'LASSO (2+ PSM)\\n{SAMPLE_SIZE} sample spectra', \n",
    "             fontweight='bold', fontsize=12, color=COLOR_2PLUS)\n",
    "ax.grid(alpha=0.3)\n",
    "ax.legend(fontsize=9, loc='lower left')\n",
    "ax.set_ylim([0, 1.05])\n",
    "\n",
    "# ============================================================\n",
    "# Panel 2: LASSO (3+ PSM)\n",
    "# ============================================================\n",
    "ax = axes[1]\n",
    "\n",
    "# Individual paths\n",
    "for i, cos_path in enumerate(cosines_3plus_list):\n",
    "    ax.plot(LAMBDA_PATH, cos_path, linewidth=1.5, alpha=0.5, color=COLOR_3PLUS)\n",
    "\n",
    "# Mean path\n",
    "ax.plot(LAMBDA_PATH, cos_mean_3plus, linewidth=3, color='black', \n",
    "       label='Mean', zorder=10, linestyle='--')\n",
    "\n",
    "# Optimal lambda\n",
    "if lam_opt_3plus > 0:\n",
    "    ax.axvline(lam_opt_3plus, color=COLOR_3PLUS, linestyle='--', \n",
    "              linewidth=2.5, alpha=0.8, label=f'Optimal λ = {lam_opt_3plus:.0e}')\n",
    "else:\n",
    "    ax.axvline(LAMBDA_PATH[0], color=COLOR_3PLUS, linestyle='--', \n",
    "              linewidth=2.5, alpha=0.8, label='Optimal λ = NNLS')\n",
    "\n",
    "ax.set_xscale('log')\n",
    "ax.set_xlabel('λ (Regularization Parameter)', fontweight='bold', fontsize=11)\n",
    "ax.set_ylabel('Reconstruction Cosine', fontweight='bold', fontsize=11)\n",
    "ax.set_title(f'LASSO (3+ PSM)\\n{SAMPLE_SIZE} sample spectra', \n",
    "             fontweight='bold', fontsize=12, color=COLOR_3PLUS)\n",
    "ax.grid(alpha=0.3)\n",
    "ax.legend(fontsize=9, loc='lower left')\n",
    "ax.set_ylim([0, 1.05])\n",
    "\n",
    "# ============================================================\n",
    "# Panel 3: LASSO+MS1 (3+ PSM)\n",
    "# ============================================================\n",
    "ax = axes[2]\n",
    "\n",
    "# Individual paths\n",
    "for i, cos_path in enumerate(cosines_3plus_ms1_list):\n",
    "    ax.plot(LAMBDA_PATH, cos_path, linewidth=1.5, alpha=0.5, color=COLOR_MS1)\n",
    "\n",
    "# Mean path\n",
    "ax.plot(LAMBDA_PATH, cos_mean_3plus_ms1, linewidth=3, color='black', \n",
    "       label='Mean', zorder=10, linestyle='--')\n",
    "\n",
    "# Optimal lambda\n",
    "if lam_opt_ms1 > 0:\n",
    "    ax.axvline(lam_opt_ms1, color=COLOR_MS1, linestyle='--', \n",
    "              linewidth=2.5, alpha=0.8, label=f'Optimal λ = {lam_opt_ms1:.0e}')\n",
    "else:\n",
    "    ax.axvline(LAMBDA_PATH[0], color=COLOR_MS1, linestyle='--', \n",
    "              linewidth=2.5, alpha=0.8, label='Optimal λ = NNLS')\n",
    "\n",
    "ax.set_xscale('log')\n",
    "ax.set_xlabel('λ (Regularization Parameter)', fontweight='bold', fontsize=11)\n",
    "ax.set_ylabel('Reconstruction Cosine', fontweight='bold', fontsize=11)\n",
    "ax.set_title(f'LASSO+MS1 (3+ PSM)\\n{SAMPLE_SIZE} sample spectra', \n",
    "             fontweight='bold', fontsize=12, color=COLOR_MS1)\n",
    "ax.grid(alpha=0.3)\n",
    "ax.legend(fontsize=9, loc='lower left')\n",
    "ax.set_ylim([0, 1.05])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIG_DIR / 'regularization_paths_three_models.png', dpi=150, facecolor='white')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n✓ Saved: {FIG_DIR / 'regularization_paths_three_models.png'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "VALIDATION WITH OPTIMAL LAMBDA\n",
      "======================================================================\n",
      "\n",
      "Validating LASSO (2+ PSM) (λ=NNLS)...\n",
      "  Completed in 8.0s\n",
      "\n",
      "Validating LASSO (3+ PSM) (λ=NNLS)...\n",
      "  Completed in 8.0s\n",
      "\n",
      "Validating LASSO+MS1 (3+ PSM) (λ=1e-04)...\n",
      "  Completed in 8.5s\n",
      "\n",
      "✓ Saved: /tmp/lasso_validation_three_models.csv\n",
      "  Total PSMs: 220,717\n",
      "  Total spectra: 51,548\n",
      "\n",
      "  Results per model:\n",
      "    LASSO (2+ PSM)           : 29,991 spectra, 92,645 PSMs\n",
      "    LASSO (3+ PSM)           : 20,044 spectra, 72,802 PSMs\n",
      "    LASSO+MS1 (3+ PSM)       : 15,357 spectra, 55,270 PSMs\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# VALIDATION WITH OPTIMAL LAMBDA\n",
    "# ============================================================\n",
    "\n",
    "def validate_full(args):\n",
    "    sd, use_ms1, lambda_val, model_name = args\n",
    "    \n",
    "    if use_ms1:\n",
    "        X = sd['X_augmented']\n",
    "        y = sd['y_augmented']\n",
    "        X_base = sd['X_base']\n",
    "        y_base = sd['y']\n",
    "    else:\n",
    "        X = sd['X']\n",
    "        y = sd['y']\n",
    "        X_base = X\n",
    "        y_base = y\n",
    "    \n",
    "    # Fit\n",
    "    if lambda_val == 0:\n",
    "        beta, _ = nnls(X, y)\n",
    "    else:\n",
    "        model = Lasso(alpha=lambda_val, positive=True,\n",
    "                     fit_intercept=False, max_iter=10000, tol=1e-8)\n",
    "        model.fit(X, y)\n",
    "        beta = model.coef_\n",
    "    \n",
    "    # Normalize beta\n",
    "    beta_peptides = beta[:sd['n_psm']]\n",
    "    if beta_peptides.sum() > 0:\n",
    "        beta_norm = beta_peptides / beta_peptides.sum()\n",
    "    else:\n",
    "        beta_norm = beta_peptides\n",
    "    \n",
    "    # Predict on spectral part\n",
    "    y_pred = X_base @ beta_peptides\n",
    "    cos = cosine(y_base, y_pred)\n",
    "    \n",
    "    # Per-peptide results\n",
    "    results = []\n",
    "    for j, psm in enumerate(sd['psm_info']):\n",
    "        results.append({\n",
    "            'spectrum_key': sd['spectrum_key'],\n",
    "            'peptide': psm['peptide'],\n",
    "            'model': model_name,\n",
    "            'lambda': lambda_val,\n",
    "            'beta': float(beta_norm[j]),\n",
    "            'by_int_frac': psm.get('by_int_frac', np.nan),\n",
    "            'prosit_cosine': psm.get('prosit_cosine', np.nan),\n",
    "            'hyperscore': psm['hyperscore'],\n",
    "            'n_psm': sd['n_psm'],\n",
    "            'cosine': cos\n",
    "        })\n",
    "    \n",
    "    return results\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"VALIDATION WITH OPTIMAL LAMBDA\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "val_results = []\n",
    "\n",
    "# Model 1: LASSO (2+ PSM)\n",
    "model_name = 'LASSO (2+ PSM)'\n",
    "lam_opt = optimal[model_name]\n",
    "lam_str = \"NNLS\" if lam_opt == 0 else f\"{lam_opt:.0e}\"\n",
    "print(f\"\\nValidating {model_name} (λ={lam_str})...\")\n",
    "\n",
    "tasks = [(sd, False, lam_opt, model_name) for sd in val_2plus]\n",
    "\n",
    "t0 = time.time()\n",
    "with Pool(cpu_count()) as pool:\n",
    "    results = pool.map(validate_full, tasks, chunksize=100)\n",
    "t1 = time.time()\n",
    "\n",
    "for batch in results:\n",
    "    val_results.extend(batch)\n",
    "\n",
    "print(f\"  Completed in {t1-t0:.1f}s\")\n",
    "\n",
    "# Model 2: LASSO (3+ PSM)\n",
    "model_name = 'LASSO (3+ PSM)'\n",
    "lam_opt = optimal[model_name]\n",
    "lam_str = \"NNLS\" if lam_opt == 0 else f\"{lam_opt:.0e}\"\n",
    "print(f\"\\nValidating {model_name} (λ={lam_str})...\")\n",
    "\n",
    "tasks = [(sd, False, lam_opt, model_name) for sd in val_3plus]\n",
    "\n",
    "t0 = time.time()\n",
    "with Pool(cpu_count()) as pool:\n",
    "    results = pool.map(validate_full, tasks, chunksize=100)\n",
    "t1 = time.time()\n",
    "\n",
    "for batch in results:\n",
    "    val_results.extend(batch)\n",
    "\n",
    "print(f\"  Completed in {t1-t0:.1f}s\")\n",
    "\n",
    "# Model 3: LASSO+MS1 (3+ PSM)\n",
    "model_name = 'LASSO+MS1 (3+ PSM)'\n",
    "lam_opt = optimal[model_name]\n",
    "lam_str = \"NNLS\" if lam_opt == 0 else f\"{lam_opt:.0e}\"\n",
    "print(f\"\\nValidating {model_name} (λ={lam_str})...\")\n",
    "\n",
    "tasks = [(sd, True, lam_opt, model_name) for sd in val_3plus_ms1]\n",
    "\n",
    "t0 = time.time()\n",
    "with Pool(cpu_count()) as pool:\n",
    "    results = pool.map(validate_full, tasks, chunksize=100)\n",
    "t1 = time.time()\n",
    "\n",
    "for batch in results:\n",
    "    val_results.extend(batch)\n",
    "\n",
    "print(f\"  Completed in {t1-t0:.1f}s\")\n",
    "\n",
    "# Save results\n",
    "df_val = pd.DataFrame(val_results)\n",
    "df_val.to_csv('/tmp/lasso_validation_three_models.csv', index=False)\n",
    "\n",
    "print(f\"\\n✓ Saved: /tmp/lasso_validation_three_models.csv\")\n",
    "print(f\"  Total PSMs: {len(df_val):,}\")\n",
    "print(f\"  Total spectra: {df_val['spectrum_key'].nunique():,}\")\n",
    "print(f\"\\n  Results per model:\")\n",
    "for model in df_val['model'].unique():\n",
    "    n_spectra = df_val[df_val['model'] == model]['spectrum_key'].nunique()\n",
    "    n_psms = len(df_val[df_val['model'] == model])\n",
    "    print(f\"    {model:25s}: {n_spectra:,} spectra, {n_psms:,} PSMs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "BETA PREDICTION QUALITY\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2160x1440 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Saved: /tmp/lasso_figures/beta_predictions_quality.png\n",
      "\n",
      "======================================================================\n",
      "BETA PREDICTION CORRELATIONS - SUMMARY\n",
      "======================================================================\n",
      "\n",
      "Model                      β~FragShare     β~Prosit  n_FragShare     n_Prosit\n",
      "-------------------------------------------------------------------------------------\n",
      "LASSO (2+ PSM)                   0.661        0.628       92,639       92,645\n",
      "LASSO (3+ PSM)                   0.703        0.663       72,801       72,802\n",
      "LASSO+MS1 (3+ PSM)               0.570        0.621       55,270       55,270\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# VISUALIZATION: BETA PREDICTIONS vs GROUND TRUTH\n",
    "# ============================================================\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"BETA PREDICTION QUALITY\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "\n",
    "COLOR_2PLUS = '#E63946'\n",
    "COLOR_3PLUS = '#F77F00'\n",
    "COLOR_MS1 = '#457B9D'\n",
    "\n",
    "colors = {\n",
    "    'LASSO (2+ PSM)': COLOR_2PLUS,\n",
    "    'LASSO (3+ PSM)': COLOR_3PLUS,\n",
    "    'LASSO+MS1 (3+ PSM)': COLOR_MS1\n",
    "}\n",
    "\n",
    "# ============================================================\n",
    "# ROW 1: BETA vs FRAGSHARE (by_int_frac)\n",
    "# ============================================================\n",
    "\n",
    "for idx, model in enumerate(['LASSO (2+ PSM)', 'LASSO (3+ PSM)', 'LASSO+MS1 (3+ PSM)']):\n",
    "    ax = axes[0, idx]\n",
    "    \n",
    "    subset = df_val[df_val['model'] == model]\n",
    "    valid = subset.dropna(subset=['by_int_frac'])\n",
    "    valid = valid[valid['by_int_frac'] > 0]\n",
    "    \n",
    "    if len(valid) > 0:\n",
    "        # Sample for visualization\n",
    "        sample = valid.sample(min(3000, len(valid)), random_state=42)\n",
    "        \n",
    "        # Scatter plot\n",
    "        ax.scatter(sample['by_int_frac'], sample['beta'], \n",
    "                  alpha=0.3, s=10, color=colors[model])\n",
    "        \n",
    "        # Perfect correlation line\n",
    "        ax.plot([0, 1], [0, 1], 'k--', linewidth=2, alpha=0.7, label='Perfect')\n",
    "        \n",
    "        # Compute correlation\n",
    "        corr = valid['beta'].corr(valid['by_int_frac'])\n",
    "        \n",
    "        # Add text box with correlation\n",
    "        ax.text(0.05, 0.95, f'r = {corr:.3f}\\nn = {len(valid):,}',\n",
    "                transform=ax.transAxes, fontsize=11, fontweight='bold',\n",
    "                verticalalignment='top',\n",
    "                bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "        \n",
    "        ax.set_xlabel('FragShare (Ground Truth)', fontweight='bold', fontsize=11)\n",
    "        ax.set_ylabel('β (Predicted)', fontweight='bold', fontsize=11)\n",
    "        ax.set_title(f'{model}\\nβ vs FragShare', fontweight='bold', fontsize=12)\n",
    "        ax.set_xlim(0, 1)\n",
    "        ax.set_ylim(0, 1)\n",
    "        ax.grid(alpha=0.3)\n",
    "        ax.legend(fontsize=9)\n",
    "\n",
    "# ============================================================\n",
    "# ROW 2: BETA vs PROSIT COSINE\n",
    "# ============================================================\n",
    "\n",
    "for idx, model in enumerate(['LASSO (2+ PSM)', 'LASSO (3+ PSM)', 'LASSO+MS1 (3+ PSM)']):\n",
    "    ax = axes[1, idx]\n",
    "    \n",
    "    subset = df_val[df_val['model'] == model]\n",
    "    valid = subset.dropna(subset=['prosit_cosine'])\n",
    "    \n",
    "    if len(valid) > 0:\n",
    "        # Sample for visualization\n",
    "        sample = valid.sample(min(3000, len(valid)), random_state=42)\n",
    "        \n",
    "        # Scatter plot\n",
    "        ax.scatter(sample['prosit_cosine'], sample['beta'], \n",
    "                  alpha=0.3, s=10, color=colors[model])\n",
    "        \n",
    "        # Compute correlation\n",
    "        corr = valid['beta'].corr(valid['prosit_cosine'])\n",
    "        \n",
    "        # Add text box with correlation\n",
    "        ax.text(0.05, 0.95, f'r = {corr:.3f}\\nn = {len(valid):,}',\n",
    "                transform=ax.transAxes, fontsize=11, fontweight='bold',\n",
    "                verticalalignment='top',\n",
    "                bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "        \n",
    "        ax.set_xlabel('Prosit Cosine (Prediction)', fontweight='bold', fontsize=11)\n",
    "        ax.set_ylabel('β (Predicted)', fontweight='bold', fontsize=11)\n",
    "        ax.set_title(f'{model}\\nβ vs Prosit Cosine', fontweight='bold', fontsize=12)\n",
    "        ax.set_xlim(0, 1)\n",
    "        ax.set_ylim(0, 1)\n",
    "        ax.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIG_DIR / 'beta_predictions_quality.png', dpi=150, facecolor='white')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n✓ Saved: {FIG_DIR / 'beta_predictions_quality.png'}\")\n",
    "\n",
    "# ============================================================\n",
    "# SUMMARY TABLE: CORRELATIONS\n",
    "# ============================================================\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"BETA PREDICTION CORRELATIONS - SUMMARY\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "print(f\"\\n{'Model':25s} {'β~FragShare':>12} {'β~Prosit':>12} {'n_FragShare':>12} {'n_Prosit':>12}\")\n",
    "print(\"-\" * 85)\n",
    "\n",
    "for model in ['LASSO (2+ PSM)', 'LASSO (3+ PSM)', 'LASSO+MS1 (3+ PSM)']:\n",
    "    subset = df_val[df_val['model'] == model]\n",
    "    \n",
    "    # FragShare correlation\n",
    "    valid_frag = subset.dropna(subset=['by_int_frac'])\n",
    "    valid_frag = valid_frag[valid_frag['by_int_frac'] > 0]\n",
    "    corr_frag = valid_frag['beta'].corr(valid_frag['by_int_frac']) if len(valid_frag) > 0 else np.nan\n",
    "    n_frag = len(valid_frag)\n",
    "    \n",
    "    # Prosit correlation\n",
    "    valid_prosit = subset.dropna(subset=['prosit_cosine'])\n",
    "    corr_prosit = valid_prosit['beta'].corr(valid_prosit['prosit_cosine']) if len(valid_prosit) > 0 else np.nan\n",
    "    n_prosit = len(valid_prosit)\n",
    "    \n",
    "    print(f\"{model:25s} {corr_frag:>12.3f} {corr_prosit:>12.3f} {n_frag:>12,} {n_prosit:>12,}\")\n",
    "\n",
    "print(f\"\\n{'='*70}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "PERFORMANCE ANALYSIS\n",
      "======================================================================\n",
      "\n",
      "--- Reconstruction Quality ---\n",
      "\n",
      "Model                         Mean   Median      Std        n\n",
      "----------------------------------------------------------------------\n",
      "LASSO (2+ PSM)              0.7945   0.8400   0.1646   29,991\n",
      "LASSO (3+ PSM)              0.8026   0.8427   0.1516   20,044\n",
      "LASSO+MS1 (3+ PSM)          0.7561   0.7839   0.1564   15,357\n",
      "\n",
      "======================================================================\n",
      "BETA CORRELATIONS\n",
      "======================================================================\n",
      "\n",
      "Model                      β~FragShare     β~Prosit      β~Hyper\n",
      "----------------------------------------------------------------------\n",
      "LASSO (2+ PSM)                   0.661        0.628        0.287\n",
      "LASSO (3+ PSM)                   0.703        0.663        0.345\n",
      "LASSO+MS1 (3+ PSM)               0.570        0.621        0.219\n",
      "\n",
      "======================================================================\n",
      "STATISTICAL TESTS (Paired t-tests)\n",
      "======================================================================\n",
      "\n",
      "--- Test 1: LASSO (3+ PSM) vs LASSO (2+ PSM) ---\n",
      "  Common spectra: 6,075\n",
      "  Δ Cosine:       +0.0000\n",
      "  t-statistic:    nan\n",
      "  p-value:        nan\n",
      "  Significance:   ns\n",
      "  → No significant difference\n",
      "\n",
      "--- Test 2: LASSO+MS1 (3+ PSM) vs LASSO (3+ PSM) ---\n",
      "  Common spectra: 4,607\n",
      "  Δ Cosine:       -0.0516\n",
      "  t-statistic:    -62.848\n",
      "  p-value:        0.000e+00\n",
      "  Significance:   ***\n",
      "  → LASSO (3+ PSM) is significantly BETTER\n",
      "\n",
      "======================================================================\n",
      "PERFORMANCE BY CHIMERICITY\n",
      "======================================================================\n",
      "\n",
      "2 PSM:\n",
      "  LASSO (2+ PSM)           : 0.7780 (n=9,900)\n",
      "\n",
      "3 PSM:\n",
      "  LASSO (2+ PSM)           : 0.7942 (n=10,473)\n",
      "  LASSO (3+ PSM)           : 0.7935 (n=10,375)\n",
      "  LASSO+MS1 (3+ PSM)       : 0.7417 (n=8,280)\n",
      "\n",
      "4 PSM:\n",
      "  LASSO (2+ PSM)           : 0.8062 (n=6,664)\n",
      "  LASSO (3+ PSM)           : 0.8058 (n=6,668)\n",
      "  LASSO+MS1 (3+ PSM)       : 0.7668 (n=4,955)\n",
      "\n",
      "5 PSM:\n",
      "  LASSO (2+ PSM)           : 0.8242 (n=2,954)\n",
      "  LASSO (3+ PSM)           : 0.8273 (n=3,001)\n",
      "  LASSO+MS1 (3+ PSM)       : 0.7870 (n=2,122)\n",
      "\n",
      "======================================================================\n",
      "✓ Performance analysis complete\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# PERFORMANCE ANALYSIS: THREE MODELS\n",
    "# ============================================================\n",
    "\n",
    "from scipy.stats import ttest_rel\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"PERFORMANCE ANALYSIS\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "# Reconstruction quality\n",
    "print(f\"\\n--- Reconstruction Quality ---\")\n",
    "print(f\"\\n{'Model':25s} {'Mean':>8s} {'Median':>8s} {'Std':>8s} {'n':>8s}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for model in ['LASSO (2+ PSM)', 'LASSO (3+ PSM)', 'LASSO+MS1 (3+ PSM)']:\n",
    "    subset = df_val[df_val['model'] == model]\n",
    "    cos_per_spectrum = subset.groupby('spectrum_key')['cosine'].first()\n",
    "    \n",
    "    print(f\"{model:25s} {cos_per_spectrum.mean():>8.4f} {cos_per_spectrum.median():>8.4f} \"\n",
    "          f\"{cos_per_spectrum.std():>8.4f} {len(cos_per_spectrum):>8,}\")\n",
    "\n",
    "# Beta correlations\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"BETA CORRELATIONS\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "print(f\"\\n{'Model':25s} {'β~FragShare':>12} {'β~Prosit':>12} {'β~Hyper':>12}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for model in ['LASSO (2+ PSM)', 'LASSO (3+ PSM)', 'LASSO+MS1 (3+ PSM)']:\n",
    "    subset = df_val[df_val['model'] == model]\n",
    "    \n",
    "    # Filter valid\n",
    "    valid = subset.dropna(subset=['by_int_frac'])\n",
    "    valid = valid[valid['by_int_frac'] > 0]\n",
    "    \n",
    "    corr_frag = valid['beta'].corr(valid['by_int_frac'])\n",
    "    corr_prosit = valid['beta'].corr(valid['prosit_cosine'])\n",
    "    corr_hyper = valid['beta'].corr(valid['hyperscore'])\n",
    "    \n",
    "    print(f\"{model:25s} {corr_frag:>12.3f} {corr_prosit:>12.3f} {corr_hyper:>12.3f}\")\n",
    "\n",
    "# Statistical tests\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"STATISTICAL TESTS (Paired t-tests)\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "# Test 1: LASSO (3+ PSM) vs LASSO (2+ PSM)\n",
    "print(f\"\\n--- Test 1: LASSO (3+ PSM) vs LASSO (2+ PSM) ---\")\n",
    "\n",
    "cos_2plus = df_val[df_val['model'] == 'LASSO (2+ PSM)'].groupby('spectrum_key')['cosine'].first()\n",
    "cos_3plus = df_val[df_val['model'] == 'LASSO (3+ PSM)'].groupby('spectrum_key')['cosine'].first()\n",
    "\n",
    "# Find common spectra\n",
    "common_spectra = sorted(set(cos_2plus.index) & set(cos_3plus.index))\n",
    "\n",
    "if len(common_spectra) > 0:\n",
    "    cos_2_aligned = cos_2plus.loc[common_spectra]\n",
    "    cos_3_aligned = cos_3plus.loc[common_spectra]\n",
    "    \n",
    "    delta = cos_3_aligned.mean() - cos_2_aligned.mean()\n",
    "    t_stat, p_val = ttest_rel(cos_3_aligned, cos_2_aligned)\n",
    "    \n",
    "    sig = \"***\" if p_val < 0.001 else \"**\" if p_val < 0.01 else \"*\" if p_val < 0.05 else \"ns\"\n",
    "    \n",
    "    print(f\"  Common spectra: {len(common_spectra):,}\")\n",
    "    print(f\"  Δ Cosine:       {delta:+.4f}\")\n",
    "    print(f\"  t-statistic:    {t_stat:.3f}\")\n",
    "    print(f\"  p-value:        {p_val:.3e}\")\n",
    "    print(f\"  Significance:   {sig}\")\n",
    "    \n",
    "    if delta > 0 and p_val < 0.05:\n",
    "        print(f\"  → LASSO (3+ PSM) is significantly BETTER\")\n",
    "    elif delta < 0 and p_val < 0.05:\n",
    "        print(f\"  → LASSO (2+ PSM) is significantly BETTER\")\n",
    "    else:\n",
    "        print(f\"  → No significant difference\")\n",
    "else:\n",
    "    print(f\"  No common spectra for comparison\")\n",
    "\n",
    "# Test 2: LASSO+MS1 (3+ PSM) vs LASSO (3+ PSM)\n",
    "print(f\"\\n--- Test 2: LASSO+MS1 (3+ PSM) vs LASSO (3+ PSM) ---\")\n",
    "\n",
    "cos_lasso_3 = df_val[df_val['model'] == 'LASSO (3+ PSM)'].groupby('spectrum_key')['cosine'].first()\n",
    "cos_ms1 = df_val[df_val['model'] == 'LASSO+MS1 (3+ PSM)'].groupby('spectrum_key')['cosine'].first()\n",
    "\n",
    "# Find common spectra\n",
    "common_spectra = sorted(set(cos_lasso_3.index) & set(cos_ms1.index))\n",
    "\n",
    "if len(common_spectra) > 0:\n",
    "    cos_lasso_aligned = cos_lasso_3.loc[common_spectra]\n",
    "    cos_ms1_aligned = cos_ms1.loc[common_spectra]\n",
    "    \n",
    "    delta = cos_ms1_aligned.mean() - cos_lasso_aligned.mean()\n",
    "    t_stat, p_val = ttest_rel(cos_ms1_aligned, cos_lasso_aligned)\n",
    "    \n",
    "    sig = \"***\" if p_val < 0.001 else \"**\" if p_val < 0.01 else \"*\" if p_val < 0.05 else \"ns\"\n",
    "    \n",
    "    print(f\"  Common spectra: {len(common_spectra):,}\")\n",
    "    print(f\"  Δ Cosine:       {delta:+.4f}\")\n",
    "    print(f\"  t-statistic:    {t_stat:.3f}\")\n",
    "    print(f\"  p-value:        {p_val:.3e}\")\n",
    "    print(f\"  Significance:   {sig}\")\n",
    "    \n",
    "    if delta > 0 and p_val < 0.05:\n",
    "        print(f\"  → LASSO+MS1 is significantly BETTER\")\n",
    "    elif delta < 0 and p_val < 0.05:\n",
    "        print(f\"  → LASSO (3+ PSM) is significantly BETTER\")\n",
    "    else:\n",
    "        print(f\"  → No significant difference\")\n",
    "else:\n",
    "    print(f\"  No common spectra for comparison\")\n",
    "\n",
    "# Performance by chimericity\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"PERFORMANCE BY CHIMERICITY\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "for n_psm in sorted(df_val['n_psm'].unique()):\n",
    "    print(f\"\\n{n_psm} PSM:\")\n",
    "    for model in ['LASSO (2+ PSM)', 'LASSO (3+ PSM)', 'LASSO+MS1 (3+ PSM)']:\n",
    "        subset = df_val[(df_val['model'] == model) & (df_val['n_psm'] == n_psm)]\n",
    "        if len(subset) > 0:\n",
    "            cos_mean = subset.groupby('spectrum_key')['cosine'].first().mean()\n",
    "            n_spec = subset['spectrum_key'].nunique()\n",
    "            print(f\"  {model:25s}: {cos_mean:.4f} (n={n_spec:,})\")\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"✓ Performance analysis complete\")\n",
    "print(f\"{'='*70}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "CREATING VISUALIZATIONS\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1680x1200 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Saved: /tmp/lasso_figures/model_comparison_validation.png\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# VISUALIZATION: MODEL COMPARISON\n",
    "# ============================================================\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"CREATING VISUALIZATIONS\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "COLOR_2PLUS = '#E63946'\n",
    "COLOR_3PLUS = '#F77F00'\n",
    "COLOR_MS1 = '#457B9D'\n",
    "\n",
    "colors = {\n",
    "    'LASSO (2+ PSM)': COLOR_2PLUS,\n",
    "    'LASSO (3+ PSM)': COLOR_3PLUS,\n",
    "    'LASSO+MS1 (3+ PSM)': COLOR_MS1\n",
    "}\n",
    "\n",
    "# Panel 1: Cosine Distribution\n",
    "ax = axes[0, 0]\n",
    "\n",
    "for model in ['LASSO (2+ PSM)', 'LASSO (3+ PSM)', 'LASSO+MS1 (3+ PSM)']:\n",
    "    subset = df_val[df_val['model'] == model]\n",
    "    cos_vals = subset.groupby('spectrum_key')['cosine'].first()\n",
    "    \n",
    "    ax.hist(cos_vals, bins=40, alpha=0.5, \n",
    "           label=model, color=colors[model], edgecolor='white')\n",
    "\n",
    "ax.set_xlabel('Reconstruction Cosine', fontweight='bold', fontsize=11)\n",
    "ax.set_ylabel('Count', fontweight='bold', fontsize=11)\n",
    "ax.set_title('Reconstruction Quality Distribution', fontweight='bold', fontsize=12)\n",
    "ax.legend(fontsize=9)\n",
    "ax.grid(alpha=0.3, axis='y')\n",
    "\n",
    "# Panel 2: Performance by Chimericity\n",
    "ax = axes[0, 1]\n",
    "\n",
    "for model in ['LASSO (2+ PSM)', 'LASSO (3+ PSM)', 'LASSO+MS1 (3+ PSM)']:\n",
    "    means = []\n",
    "    n_psms_list = []\n",
    "    \n",
    "    for n_psm in sorted(df_val['n_psm'].unique()):\n",
    "        subset = df_val[(df_val['model'] == model) & (df_val['n_psm'] == n_psm)]\n",
    "        if len(subset) > 0:\n",
    "            mean_cos = subset.groupby('spectrum_key')['cosine'].first().mean()\n",
    "            means.append(mean_cos)\n",
    "            n_psms_list.append(n_psm)\n",
    "    \n",
    "    ax.plot(n_psms_list, means, marker='o', linewidth=2.5, \n",
    "           label=model, color=colors[model])\n",
    "\n",
    "ax.set_xlabel('Number of PSMs', fontweight='bold', fontsize=11)\n",
    "ax.set_ylabel('Mean Cosine', fontweight='bold', fontsize=11)\n",
    "ax.set_title('Performance by Chimericity', fontweight='bold', fontsize=12)\n",
    "ax.legend(fontsize=9)\n",
    "ax.grid(alpha=0.3)\n",
    "\n",
    "# Panel 3: Beta vs FragShare (3+ PSM models only)\n",
    "ax = axes[1, 0]\n",
    "\n",
    "for model in ['LASSO (3+ PSM)', 'LASSO+MS1 (3+ PSM)']:\n",
    "    subset = df_val[df_val['model'] == model]\n",
    "    valid = subset.dropna(subset=['by_int_frac'])\n",
    "    valid = valid[valid['by_int_frac'] > 0]\n",
    "    \n",
    "    sample = valid.sample(min(2000, len(valid)), random_state=42)\n",
    "    \n",
    "    ax.scatter(sample['by_int_frac'], sample['beta'], \n",
    "              alpha=0.3, s=10, label=model, color=colors[model])\n",
    "\n",
    "ax.plot([0, 1], [0, 1], 'k--', linewidth=1.5, alpha=0.5, label='Perfect correlation')\n",
    "ax.set_xlabel('FragShare (Ground Truth)', fontweight='bold', fontsize=11)\n",
    "ax.set_ylabel('β (Predicted)', fontweight='bold', fontsize=11)\n",
    "ax.set_title('Beta vs FragShare (3+ PSM Models)', fontweight='bold', fontsize=12)\n",
    "ax.set_xlim(0, 1)\n",
    "ax.set_ylim(0, 1)\n",
    "ax.legend(fontsize=9)\n",
    "ax.grid(alpha=0.3)\n",
    "\n",
    "# Panel 4: Boxplot Comparison\n",
    "ax = axes[1, 1]\n",
    "\n",
    "data_for_box = []\n",
    "labels = []\n",
    "\n",
    "for model in ['LASSO (2+ PSM)', 'LASSO (3+ PSM)', 'LASSO+MS1 (3+ PSM)']:\n",
    "    subset = df_val[df_val['model'] == model]\n",
    "    cos_vals = subset.groupby('spectrum_key')['cosine'].first()\n",
    "    data_for_box.append(cos_vals.values)\n",
    "    labels.append(model)\n",
    "\n",
    "bp = ax.boxplot(data_for_box, labels=labels, patch_artist=True,\n",
    "                showmeans=True, meanline=True)\n",
    "\n",
    "for patch, model in zip(bp['boxes'], labels):\n",
    "    patch.set_facecolor(colors[model])\n",
    "    patch.set_alpha(0.6)\n",
    "\n",
    "ax.set_ylabel('Reconstruction Cosine', fontweight='bold', fontsize=11)\n",
    "ax.set_title('Performance Distribution by Model', fontweight='bold', fontsize=12)\n",
    "ax.tick_params(axis='x', rotation=15)\n",
    "ax.grid(alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIG_DIR / 'model_comparison_validation.png', dpi=150, facecolor='white')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n✓ Saved: {FIG_DIR / 'model_comparison_validation.png'}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
